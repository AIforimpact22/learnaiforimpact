{
  "order": 3,
  "title": "Module 3: Modularity",
  "lessons": [
    {
      "kind": "article",
      "order": 1,
      "title": "Modularity in Coding ‚Ä¢ The ISS Analogy",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Modularity in Coding ‚Ä¢ The ISS Analogy</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 900px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner {\r\n  background: linear-gradient(120deg, #555555, #000000);\r\n  color: #FFFFFF; padding: 18px 20px;\r\n}\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Image === */\r\n.img-full { display: block; width: 100%; height: auto; border-bottom: 1px solid #EBEBEB; margin-top: 12px; border-radius: 10px; }\r\n\r\n/* === Highlight boxes === */\r\n.quick-grid { display: grid; gap: 14px; margin: 14px 0; }\r\n.box { border: 1px solid #EBEBEB; border-radius: 10px; padding: 14px; background: #fafafa; }\r\n.box h3 { margin: 0 0 6px; font-size: 17px; color: #000; }\r\n.box p { margin: 0; font-size: 15px; }\r\n\r\n/* Responsive */\r\n@media (min-width: 720px) { .quick-grid { grid-template-columns: repeat(2, 1fr); } }\r\n\r\n/* === Footer note === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Concepts</small>\r\n        <h1>Modularity in Coding</h1>\r\n        <p>Why modular design solves complexity in AI-assisted development</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          When we develop code with AI, we often hit a limitation: our scripts can grow large and unwieldy.  \r\n          Each time we want to improve them, it becomes harder to communicate the entire script back to the AI.  \r\n          The solution is <strong>modularity</strong>.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- ISS ANALOGY -->\r\n    <section class=\"section-card\" id=\"analogy\">\r\n      <div class=\"banner\">\r\n        <small>Analogy</small>\r\n        <h1>The International Space Station</h1>\r\n        <p>A powerful metaphor for modularity</p>\r\n      </div>\r\n      <img\r\n        class=\"img-full\"\r\n        src=\"https://images-assets.nasa.gov/image/iss056e201248/iss056e201248~large.jpg\"\r\n        alt=\"International Space Station from NASA\"\r\n      />\r\n      <div class=\"body\">\r\n        <p>\r\n          Think of the <strong>International Space Station (ISS)</strong>.  \r\n          It wasn‚Äôt built all at once. Instead, it was assembled over time from multiple modules ‚Äî\r\n          each designed for a specific function: research, power, life support, docking.  \r\n          These modules integrate seamlessly, forming a larger, functional whole.\r\n        </p>\r\n        <p>\r\n          In the same way, code can (and should) be built from independent modules:  \r\n          smaller, focused pieces that do one thing well, and can be integrated into a larger application.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- MODULARITY BENEFITS -->\r\n    <section class=\"section-card\" id=\"benefits\">\r\n      <div class=\"banner\">\r\n        <small>Benefits</small>\r\n        <h1>Why Modularity Matters</h1>\r\n        <p>Scaling both horizontally and vertically</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <div class=\"quick-grid\">\r\n          <div class=\"box\">\r\n            <h3>üîÑ Reusability</h3>\r\n            <p>Modules can be reused across projects ‚Äî no need to reinvent the wheel.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>üì¶ Maintainability</h3>\r\n            <p>Fixes and improvements are easier to apply in smaller, isolated components.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>üìà Scalability</h3>\r\n            <p>Scale <em>horizontally</em> by adding more modules, or <em>vertically</em> by deepening each module‚Äôs capabilities.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>ü§ù Collaboration</h3>\r\n            <p>Different team members (or even AIs) can work on separate modules independently, then integrate them.</p>\r\n          </div>\r\n        </div>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- SUMMARY -->\r\n    <section class=\"section-card\" id=\"summary\">\r\n      <div class=\"banner\">\r\n        <small>Summary</small>\r\n        <h1>The Path Forward</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          Modularity is the antidote to complexity.  \r\n          Just like the ISS was built piece by piece, your software should be composed of modules ‚Äî\r\n          each handling one responsibility, all working together.  \r\n          With modularity, AI-assisted coding becomes manageable, scalable, and sustainable.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n  (function(){\r\n    const now = new Date();\r\n    document.getElementById('y').textContent = now.getFullYear();\r\n    document.getElementById('d').textContent = now.toLocaleDateString(\r\n      undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n    );\r\n  })();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "715722d7-ba49-43d0-a66a-063e0f1a02e5"
    },
    {
      "kind": "article",
      "order": 2,
      "title": "Streamlit Modularity ‚Ä¢ Minimal app.py + pages",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Streamlit Modularity ‚Ä¢ Minimal app.py + pages/</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 1000px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Code blocks === */\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\n/* === Footer === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n\r\n/* === Video embed (added) === */\r\n.video-embed { position: relative; border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden; box-shadow: 0 1px 2px rgba(0,0,0,.04); }\r\n.video-embed::before { content: \"\"; display: block; padding-top: 56.25%; } /* 16:9 */\r\n.video-embed iframe { position: absolute; inset: 0; width: 100%; height: 100%; border: 0; }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- VIDEO (added on top) -->\r\n    <section class=\"section-card\" id=\"video\">\r\n      <div class=\"banner\">\r\n        <small>Video</small>\r\n        <h1>Watch: Streamlit Modularity ‚Ä¢ Minimal app.py + pages</h1>\r\n        <p>Quick walkthrough of the modular layout and pages/ structure</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <div class=\"video-embed\">\r\n          <iframe width=\"1047\" height=\"473\" src=\"https://www.youtube.com/embed/Zlcix_RR1wI\" title=\"Streamlit Modularity ‚Ä¢ Minimal app.py + pages\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n        </div>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Streamlit ‚Ä¢ Modularity</small>\r\n        <h1>Minimal app.py + pages/ (Prompt-Driven Split)</h1>\r\n        <p>Keep app.py tiny, move features into pages/, share utilities in lib_data.py</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          same script that we had before which was three pages but in one script, we write in chatgpt to make it modular by a prompt like below<br>\r\n          <span class=\"inline\">'re-write the script to split to be a minimal app.py and the rest pages in the pages directory'</span>\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REPO LAYOUT -->\r\n    <section class=\"section-card\" id=\"layout\">\r\n      <div class=\"banner\">\r\n        <small>Structure</small>\r\n        <h1>Repository Layout</h1>\r\n        <p>Exactly as produced by your prompt</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>.\r\n‚îú‚îÄ app.py\r\n‚îú‚îÄ lib_data.py\r\n‚îî‚îÄ pages/\r\n   ‚îú‚îÄ 1_Home.py\r\n   ‚îú‚îÄ 2_Visualization.py\r\n   ‚îî‚îÄ 3_Data_View.py\r\n</pre>\r\n        <p>\r\n          Streamlit auto-discovers files under <span class=\"inline\">pages/</span> and shows them in the sidebar.\r\n          The numeric prefixes (<strong>1_</strong>, <strong>2_</strong>, <strong>3_</strong>) control the order.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- HOW TO RUN -->\r\n    <section class=\"section-card\" id=\"run\">\r\n      <div class=\"banner\">\r\n        <small>Run</small>\r\n        <h1>Run in Codespaces</h1>\r\n        <p>Install dependencies ‚Üí run Streamlit ‚Üí open port</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>In your Codespaces terminal:</p>\r\n<pre>pip install streamlit pandas numpy\r\nstreamlit run app.py --server.address 0.0.0.0 --server.port 8000</pre>\r\n        <p>Then click <strong>Open in Browser</strong> (or use the Ports panel ‚Üí port <strong>8000</strong>).</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- app.py -->\r\n    <section class=\"section-card\" id=\"app\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>app.py (Minimal)</h1>\r\n        <p>Landing page only ‚Äî pages live in /pages</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># app.py\r\nimport streamlit as st\r\n\r\nst.set_page_config(page_title=\"CSV Explorer\", page_icon=\"üìà\", layout=\"centered\")\r\n\r\nst.title(\"CSV Explorer\")\r\nst.caption(\"Use the left sidebar to open pages: Home, Visualization, Data View.\")\r\nst.markdown(\r\n    \"- Start on **Home** to load a CSV (or use the demo dataset).\\n\"\r\n    \"- Then try **Visualization** and **Data View**.\"\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- lib_data.py -->\r\n    <section class=\"section-card\" id=\"lib\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>lib_data.py (Shared Utilities)</h1>\r\n        <p>Loaders, parsers, filters, resampling, sidebars</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># lib_data.py\r\nimport io\r\nfrom pathlib import Path\r\nfrom typing import Optional, Tuple, List\r\n\r\nimport numpy as np\r\nimport pandas as pd\r\nimport streamlit as st\r\n\r\nFALLBACK_PATH = Path(\"data\") / \"weather.csv\"\r\nFREQ_MAP = {\"Off\": None, \"D (Daily)\": \"D\", \"W (Weekly)\": \"W\", \"M (Monthly)\": \"M\"}\r\n\r\n# ---------- Loaders ----------\r\n@st.cache_data(show_spinner=False)\r\ndef read_csv_from_bytes(content: bytes) -> Optional[pd.DataFrame]:\r\n    try:\r\n        df = pd.read_csv(io.BytesIO(content))\r\n        return coerce_common_datetime_cols(df)\r\n    except Exception as e:\r\n        st.error(f\"Could not read uploaded CSV: {e}\")\r\n        return None\r\n\r\n@st.cache_data(show_spinner=False)\r\ndef read_csv_from_path(path_str: str) -> Optional[pd.DataFrame]:\r\n    try:\r\n        df = pd.read_csv(path_str)\r\n        return coerce_common_datetime_cols(df)\r\n    except Exception as e:\r\n        st.error(f\"Could not read CSV at {path_str}: {e}\")\r\n        return None\r\n\r\n@st.cache_data(show_spinner=False)\r\ndef demo_dataset() -> pd.DataFrame:\r\n    dates = pd.date_range(\"2024-01-01\", periods=180, freq=\"D\")\r\n    x = np.arange(len(dates))\r\n    return pd.DataFrame(\r\n        {\r\n            \"Date\": dates,\r\n            \"TempC\": 15 + 7 * np.sin(x / 10) + np.random.normal(0, 1.4, len(dates)),\r\n            \"Rain_mm\": np.clip(np.random.gamma(1.8, 1.0, len(dates)) - 1.0, 0, None),\r\n            \"Wind_kmh\": 12 + np.random.normal(0, 3, len(dates)),\r\n        }\r\n    )\r\n\r\n# ---------- Data utilities ----------\r\ndef coerce_common_datetime_cols(df: pd.DataFrame) -> pd.DataFrame:\r\n    for col in df.columns:\r\n        name = str(col).lower()\r\n        if name in (\"date\", \"time\", \"timestamp\", \"datetime\"):\r\n            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\r\n    return df\r\n\r\ndef find_datetime_columns(df: pd.DataFrame) -> List[str]:\r\n    return [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]\r\n\r\ndef numeric_columns(df: pd.DataFrame) -> List[str]:\r\n    return df.select_dtypes(include=\"number\").columns.tolist()\r\n\r\ndef filter_by_date(\r\n    df: pd.DataFrame, date_col: str, key_prefix: str = \"range_\"\r\n) -> Tuple[pd.DataFrame, Optional[pd.Timestamp], Optional[pd.Timestamp]]:\r\n    dmin, dmax = df[date_col].min(), df[date_col].max()\r\n    if pd.isna(dmin) or pd.isna(dmax):\r\n        st.info(\"Date column contains invalid values; showing all rows.\")\r\n        return df, None, None\r\n    start, end = st.date_input(\r\n        \"Date range\",\r\n        value=(dmin.date(), dmax.date()),\r\n        min_value=dmin.date(),\r\n        max_value=dmax.date(),\r\n        key=f\"{key_prefix}date_range\",\r\n    )\r\n    if start and end:\r\n        mask = (df[date_col] >= pd.to_datetime(start)) & (df[date_col] <= pd.to_datetime(end))\r\n        return df.loc[mask].copy(), pd.to_datetime(start), pd.to_datetime(end)\r\n    return df, None, None\r\n\r\ndef resample_df(df: pd.DataFrame, date_col: str, cols: List[str], freq: Optional[str], how: str) -> pd.DataFrame:\r\n    if not freq:\r\n        return df.set_index(date_col)[cols].sort_index()\r\n    agg = \"mean\" if how == \"Mean\" else \"sum\"\r\n    return df.set_index(date_col)[cols].sort_index().resample(freq).agg(agg)\r\n\r\ndef apply_rolling(df: pd.DataFrame, window: int) -> pd.DataFrame:\r\n    return df.rolling(window, min_periods=1).mean() if window and window > 1 else df\r\n\r\ndef normalize_01(df: pd.DataFrame) -> pd.DataFrame:\r\n    def _scale(s: pd.Series) -> pd.Series:\r\n        mn, mx = s.min(), s.max()\r\n        return (s - mn) / (mx - mn) if pd.notna(mn) and pd.notna(mx) and mx != mn else s * 0\r\n    return df.apply(_scale, axis=0)\r\n\r\n# ---------- Sidebars ----------\r\ndef sidebar_data_source() -> tuple[pd.DataFrame, Optional[str], str]:\r\n    st.sidebar.header(\"üóÇÔ∏è Data\")\r\n    uploaded = st.sidebar.file_uploader(\"Upload CSV\", type=[\"csv\"], key=\"uploader\")\r\n    if uploaded is not None:\r\n        df = read_csv_from_bytes(uploaded.read())\r\n        source_label = \"Uploaded file\"\r\n    elif FALLBACK_PATH.exists():\r\n        df = read_csv_from_path(str(FALLBACK_PATH))\r\n        source_label = f\"{FALLBACK_PATH}\"\r\n    else:\r\n        st.sidebar.info(\"No file uploaded and no local CSV found ‚Äî using demo data.\")\r\n        df = demo_dataset()\r\n        source_label = \"Demo dataset\"\r\n\r\n    if df is None or df.empty:\r\n        st.sidebar.error(\"No data to show.\")\r\n        st.stop()\r\n\r\n    st.sidebar.caption(f\"**Source:** {source_label}  ‚Ä¢  **Rows:** {len(df):,}  ‚Ä¢  **Columns:** {len(df.columns)}\")\r\n\r\n    # Date column manage/parse\r\n    dt_cols = find_datetime_columns(df)\r\n    date_col: Optional[str] = None\r\n    if dt_cols:\r\n        date_col = st.sidebar.selectbox(\"Date column\", dt_cols, index=0, key=\"date_col\")\r\n    else:\r\n        st.sidebar.warning(\"No datetime column detected.\")\r\n        try_col = st.sidebar.selectbox(\"Parse a column as dates (optional)\", [\"<none>\"] + df.columns.tolist(), index=0, key=\"try_parse\")\r\n        if try_col != \"<none>\":\r\n            try:\r\n                df[try_col] = pd.to_datetime(df[try_col], errors=\"coerce\")\r\n                if df[try_col].notna().any():\r\n                    date_col = try_col\r\n                    st.sidebar.success(f\"Parsed '{try_col}' as datetime.\")\r\n                else:\r\n                    st.sidebar.error(f\"Parsing '{try_col}' produced all NaT.\")\r\n            except Exception as e:\r\n                st.sidebar.error(f\"Failed to parse '{try_col}' as datetime: {e}\")\r\n\r\n    # Cache tools\r\n    st.sidebar.header(\"üßπ Maintenance\")\r\n    if st.sidebar.button(\"Clear cache\", use_container_width=False):\r\n        st.cache_data.clear()\r\n        st.sidebar.success(\"Cache cleared.\")\r\n\r\n    return df, date_col, source_label\r\n\r\ndef sidebar_chart_options(df: pd.DataFrame, key_prefix: str = \"viz_\") -> dict:\r\n    st.sidebar.header(\"üìä Chart Options\")\r\n    num_cols = numeric_columns(df)\r\n    if not num_cols:\r\n        st.sidebar.warning(\"No numeric columns found.\")\r\n        selected_cols = []\r\n    else:\r\n        selected_cols = st.sidebar.multiselect(\"Metrics to plot\", options=num_cols, default=num_cols[:1], key=f\"{key_prefix}metrics\")\r\n\r\n    freq_choice = st.sidebar.selectbox(\r\n        \"Resample (if dated)\", options=list(FREQ_MAP.keys()), index=0, key=f\"{key_prefix}freq\"\r\n    )\r\n    agg = st.sidebar.radio(\"Aggregation\", [\"Mean\", \"Sum\"], horizontal=True, index=0, key=f\"{key_prefix}agg\")\r\n    roll = st.sidebar.slider(\"Rolling average window\", min_value=1, max_value=60, value=1, key=f\"{key_prefix}roll\")\r\n    norm = st.sidebar.checkbox(\"Normalize each series to 0‚Äì1\", value=False, key=f\"{key_prefix}norm\")\r\n    chart_kind = st.sidebar.selectbox(\"Chart type\", [\"Line\", \"Area\", \"Bar\"], index=0, key=f\"{key_prefix}kind\")\r\n\r\n    return {\r\n        \"selected_cols\": selected_cols,\r\n        \"freq_choice\": freq_choice,\r\n        \"agg\": agg,\r\n        \"roll\": roll,\r\n        \"norm\": norm,\r\n        \"chart_kind\": chart_kind,\r\n    }\r\n\r\ndef sidebar_data_view_options(df: pd.DataFrame, key_prefix: str = \"dv_\") -> dict:\r\n    st.sidebar.header(\"üîé Filter & View\")\r\n    quick_filter = st.sidebar.text_input(\"Quick text filter (matches any column)\", value=\"\", key=f\"{key_prefix}qf\")\r\n    col_choices = st.sidebar.multiselect(\"Columns to display (blank = all)\", options=df.columns.tolist(), default=[], key=f\"{key_prefix}cols\")\r\n    enable_edit = st.sidebar.checkbox(\"Enable editing (local only)\", value=False, key=f\"{key_prefix}edit\")\r\n    return {\"quick_filter\": quick_filter, \"col_choices\": col_choices, \"enable_edit\": enable_edit}\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- pages/1_Home.py -->\r\n    <section class=\"section-card\" id=\"home\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/1_Home.py</h1>\r\n        <p>Overview KPIs, preview, schema</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/1_Home.py\r\nimport pandas as pd\r\nimport streamlit as st\r\nfrom lib_data import sidebar_data_source, numeric_columns\r\n\r\nst.title(\"üè† Home\")\r\nst.caption(\"Overview of your dataset and quick stats.\")\r\n\r\ndf, date_col, _ = sidebar_data_source()\r\n\r\n# KPIs\r\nk1, k2, k3, k4 = st.columns(4)\r\nk1.metric(\"Rows\", f\"{len(df):,}\")\r\nk2.metric(\"Columns\", f\"{len(df.columns):,}\")\r\nn_num = len(numeric_columns(df))\r\nk3.metric(\"Numeric cols\", f\"{n_num:,}\")\r\nif date_col:\r\n    dmin = pd.to_datetime(df[date_col].min())\r\n    dmax = pd.to_datetime(df[date_col].max())\r\n    k4.metric(\"Date span\", f\"{str(dmin.date()) if pd.notna(dmin) else '‚Äî'} ‚Üí {str(dmax.date()) if pd.notna(dmax) else '‚Äî'}\")\r\nelse:\r\n    k4.metric(\"Date column\", \"Not set\")\r\n\r\nst.subheader(\"Preview\")\r\nst.dataframe(df.head(50), width=\"stretch\")\r\n\r\nst.subheader(\"Schema\")\r\nschema = pd.DataFrame(\r\n    {\r\n        \"dtype\": df.dtypes.astype(str),\r\n        \"non_null\": df.notna().sum(),\r\n        \"nulls\": df.isna().sum(),\r\n        \"unique\": df.nunique(dropna=True),\r\n    }\r\n)\r\nst.dataframe(schema, width=\"stretch\")\r\n\r\nst.markdown(\r\n    \"\"\"\r\n**Tips**\r\n- Upload a CSV or let the app use a demo dataset.\r\n- If your dates weren‚Äôt auto-detected, choose a column to parse in the sidebar.\r\n- Use the other pages for charts and table exploration.\r\n\"\"\"\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- pages/2_Visualization.py -->\r\n    <section class=\"section-card\" id=\"viz\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/2_Visualization.py</h1>\r\n        <p>Resample, aggregate, rolling, normalize, chart & export</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/2_Visualization.py\r\nimport streamlit as st\r\nfrom lib_data import (\r\n    sidebar_data_source,\r\n    sidebar_chart_options,\r\n    numeric_columns,\r\n    filter_by_date,\r\n    resample_df,\r\n    apply_rolling,\r\n    normalize_01,\r\n    FREQ_MAP,\r\n)\r\n\r\nst.title(\"üìä Visualization\")\r\n\r\ndf, date_col, _ = sidebar_data_source()\r\n\r\n# Guardrails\r\nif not numeric_columns(df):\r\n    st.warning(\"No numeric columns found to plot. Upload a CSV with numeric data.\")\r\n    st.stop()\r\n\r\nopts = sidebar_chart_options(df, key_prefix=\"viz_\")\r\n\r\n# Filter by date if available\r\ndf_view = df.copy()\r\nif date_col:\r\n    st.subheader(\"Filter\")\r\n    df_view, start_ts, end_ts = filter_by_date(df_view, date_col, key_prefix=\"viz_\")\r\n    if start_ts and end_ts:\r\n        st.success(f\"Showing {len[df_view):,} rows from {start_ts.date()} to {end_ts.date()}.\")\r\n    else:\r\n        st.info(f\"Showing all {len(df_view):,} rows.\")\r\n\r\n# Build series\r\nif not opts[\"selected_cols\"]:\r\n    st.warning(\"Pick at least one metric in the sidebar to plot.\")\r\n    st.stop()\r\n\r\nif date_col:\r\n    series_df = resample_df(\r\n        df_view,\r\n        date_col,\r\n        opts[\"selected_cols\"],\r\n        FREQ_MAP[opts[\"freq_choice\"]],\r\n        opts[\"agg\"],\r\n    )\r\nelse:\r\n    series_df = df_view[opts[\"selected_cols\"]]\r\n\r\nif series_df.empty:\r\n    st.warning(\"Nothing to plot with the current settings.\")\r\n    st.stop()\r\n\r\nif opts[\"roll\"] > 1:\r\n    series_df = apply_rolling(series_df, opts[\"roll\"])\r\nif opts[\"norm\"]:\r\n    series_df = normalize_01(series_df)\r\n\r\n# Render chart (auto-size; no width string)\r\nst.subheader(\"Chart\")\r\nkind = opts[\"chart_kind\"]\r\nif kind == \"Line\":\r\n    st.line_chart(series_df)\r\nelif kind == \"Area\":\r\n    st.area_chart(series_df)\r\nelse:\r\n    st.bar_chart(series_df)\r\n\r\n# Export chart data\r\nst.subheader(\"Export chart data\")\r\ncsv_bytes = series_df.reset_index().to_csv(index=False).encode(\"utf-8\")\r\nst.download_button(\r\n    \"Download chart data as CSV\",\r\n    data=csv_bytes,\r\n    file_name=\"chart_data.csv\",\r\n    mime=\"text/csv\",\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- pages/3_Data_View.py -->\r\n    <section class=\"section-card\" id=\"data-view\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/3_Data_View.py</h1>\r\n        <p>Filter, choose columns, optional editing, export</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/3_Data_View.py\r\nimport pandas as pd\r\nimport streamlit as st\r\nfrom lib_data import (\r\n    sidebar_data_source,\r\n    sidebar_data_view_options,\r\n    filter_by_date,\r\n)\r\n\r\nst.title(\"üßæ Data View\")\r\n\r\ndf, date_col, _ = sidebar_data_source()\r\nopts = sidebar_data_view_options(df, key_prefix=\"dv_\")\r\n\r\ndf_view = df.copy()\r\n\r\n# Date filter (if available)\r\nif date_col:\r\n    st.subheader(\"Date Filter\")\r\n    df_view, start_ts, end_ts = filter_by_date(df_view, date_col, key_prefix=\"dv_\")\r\n    if start_ts and end_ts:\r\n        st.success(f\"Rows from {start_ts.date()} to {end_ts.date()}: {len(df_view):,}\")\r\n\r\n# Quick text filter across all columns\r\nq = (opts[\"quick_filter\"] or \"\").strip().lower()\r\nif q:\r\n    mask = df_view.astype(str).apply(lambda col: col.str.lower().str.contains(q, na=False))\r\n    df_view = df_view[mask.any(axis=1)]\r\n\r\n# Column subset\r\ncols = opts[\"col_choices\"] or list(df_view.columns)\r\nmissing = [c for c in cols if c not in df_view.columns]\r\nif missing:\r\n    st.warning(f\"Some selected columns are missing: {missing}\")\r\ncols = [c for c in cols if c in df_view.columns]\r\ndf_view = df_view[cols]\r\n\r\n# Editable or read-only grid\r\nst.subheader(\"Table\")\r\nif opts[\"enable_edit\"]:\r\n    st.caption(\"Editing is local to this session. Use the download button to export your changes.\")\r\n    df_display = st.data_editor(df_view, num_rows=\"dynamic\")\r\nelse:\r\n    st.caption(\"Read-only view. Use the sidebar to filter and select columns.\")\r\n    st.dataframe(df_view, width=\"stretch\")\r\n    df_display = df_view\r\n\r\n# Export\r\nst.subheader(\"Export\")\r\nout_bytes = df_display.to_csv(index=False).encode(\"utf-8\")\r\nst.download_button(\r\n    \"Download current view as CSV\",\r\n    data=out_bytes,\r\n    file_name=\"data_view.csv\",\r\n    mime=\"text/csv\",\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n  (function(){\r\n    const now = new Date();\r\n    document.getElementById('y').textContent = now.getFullYear();\r\n    document.getElementById('d').textContent = now.toLocaleDateString(\r\n      undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n    );\r\n  })();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "30119028-3910-48bb-bb97-bc3879aede12"
    },
    {
      "kind": "article",
      "order": 3,
      "title": "Add a New Page Without Changing Anything Else",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Streamlit Modularity ‚Ä¢ Add ‚Äú4_Quick_Profile‚Äù Page</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 1000px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Code blocks === */\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\n/* === Footer === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n\r\n/* === (Added) Professional video embed wrapper === */\r\n.video-wrap { display: flex; justify-content: center; align-items: center; }\r\n.video-wrap iframe { max-width: 100%; border-radius: 12px; box-shadow: 0 2px 12px rgba(0,0,0,.12); }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- VIDEO (added at top) -->\r\n    <section class=\"section-card\" id=\"video\">\r\n      <div class=\"banner\">\r\n        <small>Video</small>\r\n        <h1>Add a New Page Without Changing Anything Else</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <div class=\"video-wrap\">\r\n          <iframe width=\"1047\" height=\"473\" src=\"https://www.youtube.com/embed/pNEU-RM_muU\" title=\"Add a New Page Without Changing Anything Else\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n        </div>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Streamlit ‚Ä¢ Modularity</small>\r\n        <h1>Add a New Page to an Existing Modular App</h1>\r\n        <p>Drop a file into <code class=\"inline\">pages/</code> ‚Äî no changes anywhere else</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          Because your app is already modular, you can add brand-new functionality by simply creating a new file in\r\n          <span class=\"inline\">pages/</span>. Below is the prompt (for ChatGPT or your notes), the repository update,\r\n          and the exact code for the new <strong>‚Äú4_Quick_Profile‚Äù</strong> page.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- UPDATED PROMPT (for adding a page) -->\r\n    <section class=\"section-card\" id=\"prompt\">\r\n      <div class=\"banner\">\r\n        <small>Prompt</small>\r\n        <h1>Use This Prompt to Add the New Page</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>Use This Prompt to Add a New Page\r\nCreate a new Streamlit page for my already-modular app.\r\nThe app uses a minimal app.py and pages/ directory, plus shared helpers in lib_data.py.\r\nAdd a new file: pages/4_Quick_Profile.py that:\r\n- Loads data via lib_data.sidebar_data_source()\r\n- Shows KPIs (rows, columns, missing cells, duplicate rows)\r\n- Displays Schema & Nulls with pct_null and a CSV download\r\n- Summarizes numeric columns, shows a correlation heatmap with Altair\r\n- Adds a Distribution Explorer for a selected numeric column (bins slider, optional log y)\r\n- Shows a Categorical Overview (top-N frequencies) with an Altair bar chart + CSV download\r\n- Finishes with a ‚ÄúSample Rows‚Äù section and a note that no other files need changes.\r\nIf Altair is used, remind me to include \"altair\" in requirements.txt.</pre>\r\n        <p>\r\n          This prompt focuses on adding a <strong>new page</strong> to an <strong>existing modular app</strong> ‚Äî not re-modularizing the app.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REPO LAYOUT UPDATE -->\r\n    <section class=\"section-card\" id=\"repo\">\r\n      <div class=\"banner\">\r\n        <small>Structure</small>\r\n        <h1>Repository (Updated)</h1>\r\n        <p>Only a single new page is added</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>.\r\n‚îú‚îÄ app.py\r\n‚îú‚îÄ lib_data.py\r\n‚îî‚îÄ pages/\r\n   ‚îú‚îÄ 1_Home.py\r\n   ‚îú‚îÄ 2_Visualization.py\r\n   ‚îú‚îÄ 3_Data_View.py\r\n   ‚îî‚îÄ 4_Quick_Profile.py   <‚Äî NEW</pre>\r\n        <p>\r\n          Streamlit auto-discovers files under <span class=\"inline\">pages/</span> and shows them in the sidebar.\r\n          The numeric prefix (<strong>4_</strong>) controls ordering.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REQUIREMENTS -->\r\n    <section class=\"section-card\" id=\"reqs\">\r\n      <div class=\"banner\">\r\n        <small>Dependencies</small>\r\n        <h1>requirements.txt</h1>\r\n        <p>Add Altair (used for heatmaps & histograms)</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>streamlit\r\npandas\r\nnumpy\r\naltair</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- NEW PAGE CODE -->\r\n    <section class=\"section-card\" id=\"code\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/4_Quick_Profile.py</h1>\r\n        <p>Drop this file into <code class=\"inline\">pages/</code> ‚Äî nothing else to modify</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/4_Quick_Profile.py\r\nimport pandas as pd\r\nimport streamlit as st\r\nimport altair as alt\r\nfrom lib_data import sidebar_data_source, numeric_columns\r\n\r\nst.title(\"üîé Quick Profile\")\r\nst.caption(\"Schema, missingness, correlations, and quick distributions ‚Äî no app changes needed.\")\r\n\r\n# Load data via existing helper\r\ndf, date_col, _ = sidebar_data_source()\r\n\r\n# =========================\r\n# KPIs\r\n# =========================\r\nk1, k2, k3, k4 = st.columns(4)\r\nk1.metric(\"Rows\", f\"{len(df):,}\")\r\nk2.metric(\"Columns\", f\"{len(df.columns):,}\")\r\nk3.metric(\"Missing cells\", f\"{int(df.isna().sum().sum()):,}\")\r\nk4.metric(\"Duplicate rows\", f\"{int(df.duplicated().sum()):,}\")\r\n\r\n# =========================\r\n# Schema & Nulls\r\n# =========================\r\nst.subheader(\"Schema & Nulls\")\r\nschema = pd.DataFrame(\r\n    {\r\n        \"dtype\": df.dtypes.astype(str),\r\n        \"non_null\": df.notna().sum(),\r\n        \"nulls\": df.isna().sum(),\r\n        \"unique\": df.nunique(dropna=True),\r\n        \"pct_null\": (df.isna().mean() * 100).round(2),\r\n    }\r\n).sort_values(\"nulls\", ascending=False)\r\nst.dataframe(schema, width=\"stretch\")\r\n\r\nschema_csv = schema.to_csv(index=True).encode(\"utf-8\")\r\nst.download_button(\"‚¨áÔ∏è Download schema CSV\", data=schema_csv, file_name=\"schema_profile.csv\", mime=\"text/csv\")\r\n\r\n# =========================\r\n# Numeric summary & correlations\r\n# =========================\r\nnum_cols = numeric_columns(df)\r\nif num_cols:\r\n    st.subheader(\"Numeric Summary\")\r\n    st.dataframe(df[num_cols].describe(), width=\"stretch\")\r\n\r\n    st.subheader(\"Correlation Heatmap\")\r\n    corr = df[num_cols].corr()  # numeric-only by default\r\n    corr_long = (\r\n        corr.reset_index()\r\n        .melt(\"index\", var_name=\"col2\", value_name=\"corr\")\r\n        .rename(columns={\"index\": \"col1\"})\r\n    )\r\n    heatmap = (\r\n        alt.Chart(corr_long)\r\n        .mark_rect()\r\n        .encode(\r\n            x=alt.X(\"col1:N\", title=\"\", sort=None),\r\n            y=alt.Y(\"col2:N\", title=\"\", sort=None),\r\n            color=alt.Color(\"corr:Q\", scale=alt.Scale(scheme=\"redblue\", domain=[-1, 1])),\r\n            tooltip=[\"col1:N\", \"col2:N\", alt.Tooltip(\"corr:Q\", format=\".2f\")],\r\n        )\r\n        .properties(height=400)\r\n    )\r\n    st.altair_chart(heatmap)\r\n\r\n    st.subheader(\"Distribution Explorer\")\r\n    dist_col = st.selectbox(\"Choose a numeric column\", num_cols, index=0, key=\"prof_num_col\")\r\n    bins = st.slider(\"Bins\", min_value=5, max_value=100, value=30, key=\"prof_bins\")\r\n    logy = st.checkbox(\"Log scale (y-axis)\", value=False, key=\"prof_logy\")\r\n\r\n    # ‚úÖ Encoding-level binning (Altair-compatible across versions)\r\n    hist = (\r\n        alt.Chart(df[[dist_col]].dropna())\r\n        .mark_bar()\r\n        .encode(\r\n            x=alt.X(f\"{dist_col}:Q\", bin=alt.Bin(maxbins=bins), title=dist_col),\r\n            y=alt.Y(\"count()\", title=\"Count\", scale=alt.Scale(type=\"log\") if logy else alt.Undefined),\r\n            tooltip=[alt.Tooltip(\"count()\", title=\"Count\")],\r\n        )\r\n        .properties(height=300)\r\n    )\r\n    st.altair_chart(hist)\r\nelse:\r\n    st.info(\"No numeric columns found for summary/correlation.\")\r\n\r\n# =========================\r\n# Categorical overview\r\n# =========================\r\nst.subheader(\"Categorical Overview\")\r\ncat_cols = [c for c in df.columns if c not in num_cols]\r\nif cat_cols:\r\n    cat_col = st.selectbox(\"Choose a categorical column\", cat_cols, index=0, key=\"prof_cat_col\")\r\n    top_n = st.slider(\"Show top N categories\", 3, 30, 10, key=\"prof_topn\")\r\n    vc = (\r\n        df[cat_col]\r\n        .astype(\"string\")\r\n        .value_counts(dropna=False)\r\n        .head(top_n)\r\n        .rename_axis(cat_col)\r\n        .reset_index(name=\"count\")\r\n    )\r\n    bar = (\r\n        alt.Chart(vc)\r\n        .mark_bar()\r\n        .encode(\r\n            x=alt.X(\"count:Q\", title=\"Count\"),\r\n            y=alt.Y(f\"{cat_col}:N\", sort=\"-x\", title=cat_col),\r\n            tooltip=[cat_col, \"count\"],\r\n        )\r\n        .properties(height=300)\r\n    )\r\n    st.altair_chart(bar)\r\n    st.dataframe(vc, width=\"stretch\")\r\n\r\n    vc_csv = vc.to_csv(index=False).encode(\"utf-8\")\r\n    st.download_button(\r\n        f\"‚¨áÔ∏è Download '{cat_col}' frequency table (CSV)\",\r\n        data=vc_csv,\r\n        file_name=f\"{cat_col}_frequencies.csv\",\r\n        mime=\"text/csv\",\r\n    )\r\nelse:\r\n    st.info(\"No categorical columns detected.\")\r\n\r\n# =========================\r\n# Sample rows\r\n# =========================\r\nst.subheader(\"Sample Rows\")\r\nn_sample = st.slider(\"Rows to preview\", 5, 100, 20, key=\"prof_sample_n\")\r\nst.dataframe(df.head(n_sample), width=\"stretch\")\r\n\r\nst.caption(\"Just drop this file into the `pages/` folder. No changes to other files required.\")</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- RUN -->\r\n    <section class=\"section-card\" id=\"run\">\r\n      <div class=\"banner\">\r\n        <small>Run</small>\r\n        <h1>Run in Codespaces</h1>\r\n        <p>Install ‚Üí Run ‚Üí Open Port</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>pip install -r requirements.txt\r\nstreamlit run app.py --server.address 0.0.0.0 --server.port 8000</pre>\r\n        <p>Open the forwarded port (8000). In the sidebar you‚Äôll now see <strong>‚Äú4_Quick_Profile‚Äù</strong>.</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n  (function(){\r\n    const now = new Date();\r\n    document.getElementById('y').textContent = now.getFullYear();\r\n    document.getElementById('d').textContent = now.toLocaleDateString(\r\n      undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n    );\r\n  })();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "faf1370e-cbdf-4bc2-b677-fdda66ecbc1d"
    },
    {
      "kind": "article",
      "order": 4,
      "title": "Add a new Page: Extend your data",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Streamlit Modularity ‚Ä¢ Add \"5_Bulk_Upload_CSV\" Page</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 1000px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Video container === */\r\n.video-container {\r\n  margin-bottom: 32px;\r\n  border-radius: 12px;\r\n  overflow: hidden;\r\n  box-shadow: 0 4px 12px rgba(0,0,0,0.1);\r\n  background: #f8f9fa;\r\n  padding: 20px;\r\n}\r\n\r\n.video-container h2 {\r\n  margin: 0 0 16px 0;\r\n  font-size: 22px;\r\n  color: #333;\r\n  text-align: center;\r\n  font-weight: 600;\r\n}\r\n\r\n.video-wrapper {\r\n  position: relative;\r\n  width: 100%;\r\n  height: 0;\r\n  padding-bottom: 45.2%; /* 473/1047 aspect ratio */\r\n  border-radius: 8px;\r\n  overflow: hidden;\r\n  box-shadow: 0 2px 8px rgba(0,0,0,0.15);\r\n}\r\n\r\n.video-wrapper iframe {\r\n  position: absolute;\r\n  top: 0;\r\n  left: 0;\r\n  width: 100%;\r\n  height: 100%;\r\n}\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Code blocks === */\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\n/* === Footer === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- VIDEO SECTION -->\r\n    <div class=\"video-container\">\r\n      <div class=\"video-wrapper\">\r\n        <iframe width=\"1047\" height=\"473\" src=\"https://www.youtube.com/embed/xVg4IVdlPrI\" title=\"Add a new Page: Extend your data\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n      </div>\r\n    </div>\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Streamlit ‚Ä¢ Modularity</small>\r\n        <h1>Add a Bulk CSV Upload Page (Safe Append)</h1>\r\n        <p>Drop one new file into <code class=\"inline\">pages/</code> ‚Äî no changes anywhere else</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          This page demonstrates how modularity lets you extend your app instantly: add\r\n          <strong>pages/5_Bulk_Upload_CSV.py</strong> and you get a full UI to upload multiple CSVs, combine them,\r\n          de-duplicate, and **append safely** to a base CSV (with newline protection to avoid row merges).\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- UPDATED PROMPT (for adding THIS page) -->\r\n    <section class=\"section-card\" id=\"prompt\">\r\n      <div class=\"banner\">\r\n        <small>Prompt</small>\r\n        <h1>Use This Prompt to Add the New Page</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>Add a new Streamlit page to my already-modular app:\r\nCreate pages/5_Bulk_Upload_CSV.py that:\r\n- Lets me upload one or more CSV files\r\n- Offers flexible read options (encoding, delimiter, decimal, header, NA handling, auto-parse dates)\r\n- Standardizes column names (case/trim/space handling) and can add a source filename column\r\n- Combines uploads by union or intersection of columns; optional within-upload de-duplication\r\n- Shows previews and a combined table\r\n- Appends to a base CSV with a safe trailing-newline check to prevent row merges\r\n- Optionally de-duplicates against the base before appending\r\n- Provides a download of the combined upload\r\nNo other files should need changes. The page should rely only on pandas and streamlit.</pre>\r\n        <p>Paste the resulting file into <span class=\"inline\">pages/</span> and it will appear in the Streamlit sidebar automatically.</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REPO LAYOUT UPDATE -->\r\n    <section class=\"section-card\" id=\"repo\">\r\n      <div class=\"banner\">\r\n        <small>Structure</small>\r\n        <h1>Repository (Updated)</h1>\r\n        <p>Only one new file added under <code class=\"inline\">pages/</code></p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>.\r\n‚îú‚îÄ app.py\r\n‚îú‚îÄ lib_data.py\r\n‚îî‚îÄ pages/\r\n   ‚îú‚îÄ 1_Home.py\r\n   ‚îú‚îÄ 2_Visualization.py\r\n   ‚îú‚îÄ 3_Data_View.py\r\n   ‚îú‚îÄ 4_Quick_Profile.py\r\n   ‚îî‚îÄ 5_Bulk_Upload_CSV.py   <‚Äî NEW</pre>\r\n        <p>\r\n          Streamlit auto-discovers files under <span class=\"inline\">pages/</span> and shows them in the sidebar.\r\n          The numeric prefix (<strong>5_</strong>) controls ordering.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REQUIREMENTS -->\r\n    <section class=\"section-card\" id=\"reqs\">\r\n      <div class=\"banner\">\r\n        <small>Dependencies</small>\r\n        <h1>requirements.txt</h1>\r\n        <p>No new packages required beyond what you already use</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>streamlit\r\npandas\r\nnumpy</pre>\r\n        <p>Altair isn't required for this page. (It was only used by your Quick Profile page.)</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- NEW PAGE CODE -->\r\n    <section class=\"section-card\" id=\"code\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/5_Bulk_Upload_CSV.py</h1>\r\n        <p>Drop this file into <code class=\"inline\">pages/</code> ‚Äî nothing else to modify</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/5_Bulk_Upload_CSV.py\r\nimport io\r\nfrom pathlib import Path\r\nfrom typing import List, Optional, Tuple\r\n\r\nimport pandas as pd\r\nimport streamlit as st\r\n\r\nst.title(\"üì§ Bulk CSV Upload ‚Üí Append to Base File (safe newline)\")\r\nst.caption(\"Combine multiple CSVs and append them to /workspaces/photos/data/weather.csv without line merges.\")\r\n\r\n# -----------------------------\r\n# Constants\r\n# -----------------------------\r\nBASE_CSV_PATH = Path(\"/workspaces/photos/data/weather.csv\")\r\nBASE_CSV_PATH.parent.mkdir(parents=True, exist_ok=True)  # ensure folder exists\r\n\r\n# -----------------------------\r\n# Helpers\r\n# -----------------------------\r\ndef _standardize_cols(cols: List[str], case: str = \"keep\", trim: bool = True, spaces: str = \"keep\") -> List[str]:\r\n    out = []\r\n    for c in cols:\r\n        name = str(c)\r\n        if trim:\r\n            name = name.strip()\r\n        if spaces == \"underscore\":\r\n            name = \"_\".join(name.split())\r\n        elif spaces == \"single\":\r\n            name = \" \".join(name.split())\r\n        if case == \"lower\":\r\n            name = name.lower()\r\n        elif case == \"upper\":\r\n            name = name.upper()\r\n        out.append(name)\r\n    return out\r\n\r\ndef _coerce_common_datetime_cols(df: pd.DataFrame) -> pd.DataFrame:\r\n    for col in df.columns:\r\n        name = str(col).lower()\r\n        if name in (\"date\", \"time\", \"timestamp\", \"datetime\"):\r\n            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\r\n    return df\r\n\r\n@st.cache_data(show_spinner=False)\r\ndef _read_one_csv(\r\n    content: bytes,\r\n    encoding: str,\r\n    sep_choice: str,\r\n    decimal: str,\r\n    header_row: bool,\r\n    treat_empty_as_na: bool,\r\n    parse_dates_auto: bool,\r\n) -> pd.DataFrame:\r\n    \"\"\"Read a CSV from bytes with flexible options.\"\"\"\r\n    bio = io.BytesIO(content)\r\n    if sep_choice == \"Auto (sniff)\":\r\n        sep, engine = None, \"python\"  # python engine for sep=None sniffing\r\n    elif sep_choice == \"Comma (,)\":\r\n        sep, engine = \",\", None\r\n    elif sep_choice == \"Semicolon (;)\":\r\n        sep, engine = \";\", None\r\n    else:\r\n        sep, engine = \"\\t\", None  # Tab\r\n\r\n    na_vals = None\r\n    keep_default_na = True\r\n    if treat_empty_as_na:\r\n        na_vals = [\"\", \"NA\", \"N/A\", \"na\", \"n/a\", \"NULL\", \"null\", \"None\", \"none\"]\r\n\r\n    df = pd.read_csv(\r\n        bio,\r\n        encoding=encoding,\r\n        sep=sep,\r\n        engine=engine,\r\n        header=0 if header_row else None,\r\n        decimal=decimal,\r\n        na_values=na_vals,\r\n        keep_default_na=keep_default_na,\r\n    )\r\n    if not header_row:\r\n        df.columns = [f\"col_{i+1}\" for i in range(df.shape[1])]\r\n    if parse_dates_auto:\r\n        df = _coerce_common_datetime_cols(df)\r\n    return df\r\n\r\ndef _read_base_columns(path: Path) -> Optional[List[str]]:\r\n    if not path.exists() or path.stat().st_size == 0:\r\n        return None\r\n    try:\r\n        return pd.read_csv(path, nrows=0).columns.tolist()\r\n    except Exception as e:\r\n        st.error(f\"Couldn't read base CSV header at {path}: {e}\")\r\n        return None\r\n\r\ndef _align_to_base(df: pd.DataFrame, base_cols: List[str]) -> pd.DataFrame:\r\n    aligned = df.copy()\r\n    for c in base_cols:\r\n        if c not in aligned.columns:\r\n            aligned[c] = pd.NA\r\n    return aligned[base_cols]\r\n\r\ndef _infer_numeric(df: pd.DataFrame, columns: Optional[List[str]] = None) -> pd.DataFrame:\r\n    cols = columns or df.columns.tolist()\r\n    for c in cols:\r\n        if df[c].dtype == \"object\":\r\n            df[c] = pd.to_numeric(df[c].astype(str).str.replace(\",\", \"\", regex=False), errors=\"ignore\")\r\n    return df\r\n\r\ndef _ensure_trailing_newline(path: Path) -> None:\r\n    \"\"\"\r\n    If the file exists and the last byte isn't '\\n', append a newline.\r\n    Prevents the first appended row from merging with the last existing row.\r\n    \"\"\"\r\n    if not path.exists():\r\n        return\r\n    size = path.stat().st_size\r\n    if size == 0:\r\n        return\r\n    with path.open(\"rb\") as f:\r\n        f.seek(-1, 2)\r\n        last = f.read(1)\r\n    if last != b\"\\n\":\r\n        # append a newline safely\r\n        with path.open(\"ab\") as f:\r\n            f.write(b\"\\n\")\r\n\r\ndef _safe_append_csv(path: Path, df: pd.DataFrame) -> None:\r\n    \"\"\"Append DataFrame rows to CSV ensuring a newline boundary and consistent line endings.\"\"\"\r\n    if df.empty:\r\n        return\r\n    if path.exists() and path.stat().st_size > 0:\r\n        _ensure_trailing_newline(path)\r\n        df.to_csv(path, mode=\"a\", header=False, index=False, encoding=\"utf-8\", lineterminator=\"\\n\")\r\n    else:\r\n        # create with header\r\n        df.to_csv(path, mode=\"w\", header=True, index=False, encoding=\"utf-8\", lineterminator=\"\\n\")\r\n\r\n# -----------------------------\r\n# Sidebar\r\n# -----------------------------\r\nwith st.sidebar:\r\n    st.header(\"Upload\")\r\n    files = st.file_uploader(\"Choose one or more CSV files\", type=[\"csv\"], accept_multiple_files=True)\r\n\r\n    st.header(\"Read Options\")\r\n    encoding = st.selectbox(\"Encoding\", [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\"], index=0)\r\n    sep_choice = st.selectbox(\"Delimiter\", [\"Auto (sniff)\", \"Comma (,)\", \"Semicolon (;)\", \"Tab (\\\\t)\"], index=0)\r\n    decimal = st.selectbox(\"Decimal marker\", [\".\", \",\"], index=0)\r\n    header_row = st.checkbox(\"First row is header\", value=True)\r\n    treat_empty_as_na = st.checkbox(\"Treat empty strings as missing\", value=True)\r\n    parse_dates_auto = st.checkbox(\"Auto-parse common date/time columns\", value=True)\r\n\r\n    st.header(\"Standardize Columns\")\r\n    col_case = st.selectbox(\"Case\", [\"keep\", \"lower\", \"upper\"], index=0)\r\n    col_trim = st.checkbox(\"Trim whitespace\", value=True)\r\n    col_spaces = st.selectbox(\"Spaces\", [\"keep\", \"single\", \"underscore\"], index=0)\r\n    add_source = st.checkbox(\"Add source filename column\", value=False)\r\n    source_col_name = st.text_input(\"Source column name\", value=\"source_file\", disabled=not add_source)\r\n\r\n    st.header(\"Combine Mode\")\r\n    union_mode = st.radio(\"How to combine columns\", [\"Union by name (outer)\", \"Only common columns (inner)\"], index=0)\r\n\r\n    st.header(\"Post-processing\")\r\n    try_infer_numeric = st.checkbox(\"Try to convert numeric-looking text\", value=True)\r\n    drop_empty_cols = st.checkbox(\"Drop all-empty columns\", value=True)\r\n\r\n    st.header(\"Deduplicate (within upload)\")\r\n    dedup_mode = st.radio(\"Remove duplicates\", [\"No\", \"Across all columns\", \"Choose columns\"], index=0)\r\n\r\n    st.header(\"Cache\")\r\n    if st.button(\"Clear cache\"):\r\n        st.cache_data.clear()\r\n        st.success(\"Cache cleared.\")\r\n\r\n# -----------------------------\r\n# Step 1: Read all files\r\n# -----------------------------\r\nif not files:\r\n    st.info(\"Upload one or more CSV files to start.\")\r\n    st.stop()\r\n\r\nst.subheader(\"Step 1 ‚Äî File Summary\")\r\n\r\ndfs: List[pd.DataFrame] = []\r\nmeta: List[Tuple[str, int, int]] = []\r\n\r\nprogress = st.progress(0.0)\r\nfor i, f in enumerate(files, start=1):\r\n    df_i = _read_one_csv(\r\n        content=f.getvalue(),\r\n        encoding=encoding,\r\n        sep_choice=sep_choice,\r\n        decimal=decimal,\r\n        header_row=header_row,\r\n        treat_empty_as_na=treat_empty_as_na,\r\n        parse_dates_auto=parse_dates_auto,\r\n    )\r\n    df_i.columns = _standardize_cols(df_i.columns.tolist(), case=col_case, trim=col_trim, spaces=col_spaces)\r\n    if add_source:\r\n        df_i[source_col_name] = f.name\r\n    if try_infer_numeric:\r\n        df_i = _infer_numeric(df_i)\r\n    if drop_empty_cols:\r\n        df_i = df_i.dropna(axis=1, how=\"all\")\r\n\r\n    dfs.append(df_i)\r\n    meta.append((f.name, df_i.shape[0], df_i.shape[1]))\r\n    progress.progress(i / len(files))\r\nprogress.empty()\r\n\r\nst.dataframe(pd.DataFrame(meta, columns=[\"file\", \"rows\", \"cols\"]), width=\"stretch\")\r\n\r\nwith st.expander(\"Preview first rows of each file\"):\r\n    for f, df_i in zip(files, dfs):\r\n        st.markdown(f\"**{f.name}** ‚Äî {len(df_i):,} rows √ó {len(df_i.columns)} cols\")\r\n        st.dataframe(df_i.head(10), width=\"stretch\")\r\n\r\n# -----------------------------\r\n# Step 2: Combine uploads\r\n# -----------------------------\r\nst.subheader(\"Step 2 ‚Äî Combine\")\r\njoin_how = \"outer\" if union_mode.startswith(\"Union\") else \"inner\"\r\n\r\nif join_how == \"outer\":\r\n    ordered_cols: List[str] = []\r\n    seen = set()\r\n    for df_i in dfs:\r\n        for c in df_i.columns:\r\n            if c not in seen:\r\n                seen.add(c)\r\n                ordered_cols.append(c)\r\nelse:\r\n    common = set(dfs[0].columns)\r\n    for df_i in dfs[1:]:\r\n        common &= set(df_i.columns)\r\n    ordered_cols = [c for c in dfs[0].columns if c in common]\r\n\r\nif not ordered_cols:\r\n    st.error(\"No overlapping columns to combine. Adjust standardization or use union mode.\")\r\n    st.stop()\r\n\r\ncombined = pd.concat(\r\n    [d[ordered_cols] if join_how == \"inner\" else d.reindex(columns=ordered_cols) for d in dfs],\r\n    axis=0,\r\n    ignore_index=True,\r\n)\r\n\r\n# Within-upload dedupe\r\nbefore_rows = combined.shape[0]\r\nremoved_within = 0\r\nif dedup_mode == \"Across all columns\":\r\n    combined = combined.drop_duplicates()\r\n    removed_within = before_rows - combined.shape[0]\r\nelif dedup_mode == \"Choose columns\":\r\n    chosen = st.multiselect(\"Deduplicate on columns\", options=ordered_cols, default=ordered_cols)\r\n    if chosen:\r\n        combined = combined.drop_duplicates(subset=chosen)\r\n        removed_within = before_rows - combined.shape[0]\r\nif removed_within:\r\n    st.success(f\"Removed {removed_within:,} duplicate rows within the uploaded data.\")\r\n\r\nst.markdown(\"**Combined preview**\")\r\nst.dataframe(combined.head(100), width=\"stretch\")\r\n\r\n# -----------------------------\r\n# Step 3: Append to base CSV (SAFE)\r\n# -----------------------------\r\nst.subheader(\"Step 3 ‚Äî Append to Base CSV\")\r\nst.caption(f\"Base file path: {BASE_CSV_PATH}\")\r\n\r\nbase_cols = _read_base_columns(BASE_CSV_PATH)\r\n\r\nif base_cols is None:\r\n    st.warning(\"Base CSV does not exist or is empty. Appending will CREATE it using the combined upload's columns.\")\r\n    st.code(\", \".join(combined.columns), language=\"text\")\r\n    create_btn = st.button(f\"Create base file & write {len(combined):,} rows\")\r\n    if create_btn:\r\n        try:\r\n            _safe_append_csv(BASE_CSV_PATH, combined)\r\n            st.success(f\"Created {BASE_CSV_PATH} with {len(combined):,} rows.\")\r\n            st.toast(\"Base CSV created\", icon=\"‚úÖ\")\r\n            st.caption(\"If other pages still show old data, use their sidebar ‚Üí Clear cache.\")\r\n        except Exception as e:\r\n            st.error(f\"Failed to write base CSV: {e}\")\r\nelse:\r\n    st.markdown(\"**Base CSV schema (in order):**\")\r\n    st.code(\", \".join(base_cols), language=\"text\")\r\n\r\n    # Align to base schema\r\n    aligned = _align_to_base(combined, base_cols)\r\n\r\n    st.markdown(\"**Preview of rows to append (aligned):**\")\r\n    st.dataframe(aligned.head(30), width=\"stretch\")\r\n\r\n    # Optional dedupe vs base\r\n    st.markdown(\"**Duplicate check vs base (optional)**\")\r\n    dedupe_vs_base_mode = st.radio(\r\n        \"Avoid adding rows that already exist in the base (match by):\",\r\n        [\"Off\", \"All base columns\", \"Choose columns\"],\r\n        index=0,\r\n        horizontal=True,\r\n    )\r\n\r\n    to_write = aligned\r\n    if dedupe_vs_base_mode != \"Off\":\r\n        if dedupe_vs_base_mode == \"All base columns\":\r\n            keys = base_cols\r\n        else:\r\n            keys = st.multiselect(\"Columns to match\", options=base_cols, default=base_cols)\r\n        if keys:\r\n            # Build a string key to compare quickly (robust to dtype differences)\r\n            try:\r\n                base_keys = pd.read_csv(BASE_CSV_PATH, usecols=keys, dtype=str).astype(str)\r\n                new_keys = to_write[keys].astype(str)\r\n                new_keys[\"_key\"] = new_keys.apply(lambda r: \"¬ß\".join(r.values.tolist()), axis=1)\r\n                base_keys[\"_key\"] = base_keys.apply(lambda r: \"¬ß\".join(r.values.tolist()), axis=1)\r\n                keep_mask = ~new_keys[\"_key\"].isin(base_keys[\"_key\"])\r\n                skipped = int((~keep_mask).sum())\r\n                to_write = to_write.loc[keep_mask].copy()\r\n                if skipped:\r\n                    st.success(f\"Skipped {skipped:,} rows already present in base.\")\r\n            except Exception as e:\r\n                st.warning(f\"Base dedupe skipped due to error: {e}\")\r\n\r\n    append_btn = st.button(f\"Append {len(to_write):,} rows to base CSV (safe newline)\")\r\n    if append_btn:\r\n        try:\r\n            _safe_append_csv(BASE_CSV_PATH, to_write)\r\n            st.success(f\"Appended {len(to_write):,} rows to {BASE_CSV_PATH} safely.\")\r\n            st.toast(\"Append complete\", icon=\"‚úÖ\")\r\n            st.caption(\"If other pages still show old data, use their sidebar ‚Üí Clear cache.\")\r\n        except Exception as e:\r\n            st.error(f\"Failed to append to base CSV: {e}\")\r\n\r\n# -----------------------------\r\n# Optional download\r\n# -----------------------------\r\nst.subheader(\"Optional ‚Äî Download Combined Upload\")\r\nst.download_button(\r\n    \"‚¨áÔ∏è Download combined CSV\",\r\n    data=combined.to_csv(index=False).encode(\"utf-8\"),\r\n    file_name=\"combined_upload.csv\",\r\n    mime=\"text/csv\",\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- RUN -->\r\n    <section class=\"section-card\" id=\"run\">\r\n      <div class=\"banner\">\r\n        <small>Run</small>\r\n        <h1>Run in Codespaces</h1>\r\n        <p>Install ‚Üí Run ‚Üí Open Port</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>pip install -r requirements.txt\r\nstreamlit run app.py --server.address 0.0.0.0 --server.port 8000</pre>\r\n        <p>Open the forwarded port (8000). In the sidebar you'll now see <strong>\"5_Bulk_Upload_CSV\"</strong>.</p>\r\n        <p><em>Note:</em> The script writes to <span class=\"inline\">/workspaces/photos/data/weather.csv</span>. Make sure this path exists in your Codespace (it creates the folder if missing).</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n  (function(){\r\n    const now = new Date();\r\n    document.getElementById('y').textContent = now.getFullYear();\r\n    document.getElementById('d').textContent = now.toLocaleDateString(\r\n      undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n    );\r\n  })();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "1993f76d-acca-4ad1-be7a-eab69ec8d07b"
    },
    {
      "kind": "article",
      "order": 5,
      "title": "Helper Modules",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Streamlit Helpers ‚Ä¢ bulk_upload_utils + 5_Bulk_Upload_CSV</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 1000px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Code blocks === */\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\n/* === Video embed styling === */\r\n.video-container {\r\n  position: relative;\r\n  width: 100%;\r\n  height: 0;\r\n  padding-bottom: 56.25%; /* 16:9 aspect ratio */\r\n  margin: 20px 0;\r\n  border-radius: 10px;\r\n  overflow: hidden;\r\n  box-shadow: 0 4px 12px rgba(0,0,0,0.1);\r\n}\r\n\r\n.video-container iframe {\r\n  position: absolute;\r\n  top: 0;\r\n  left: 0;\r\n  width: 100%;\r\n  height: 100%;\r\n  border: none;\r\n}\r\n\r\n/* === Footer === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- VIDEO EMBED -->\r\n    <section class=\"section-card\" id=\"video\">\r\n      <div class=\"banner\">\r\n        <small>Tutorial</small>\r\n        <h1>Helper Modules Overview</h1>\r\n        <p>Watch the complete walkthrough of implementing helper modules in Streamlit</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <div class=\"video-container\">\r\n          <iframe src=\"https://www.youtube.com/embed/9NVlL0eH-4c\" title=\"Helper Modules\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n        </div>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Streamlit ‚Ä¢ Helpers</small>\r\n        <h1>Support Your Pages with a Helper Module</h1>\r\n        <p>Extract reusable CSV utilities ‚Üí keep pages lean, safe, and testable</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          We're adding a dedicated helper module <span class=\"inline\">bulk_upload_utils.py</span> to encapsulate\r\n          CSV reading, schema alignment, safe appends, and diagnostics. The updated page\r\n          <span class=\"inline\">pages/5_Bulk_Upload_CSV.py</span> imports those helpers ‚Äî no changes elsewhere.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REPO LAYOUT -->\r\n    <section class=\"section-card\" id=\"repo\">\r\n      <div class=\"banner\">\r\n        <small>Structure</small>\r\n        <h1>Repository Layout (Updated)</h1>\r\n        <p>New helper + updated bulk upload page</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>.\r\n‚îú‚îÄ app.py\r\n‚îú‚îÄ lib_data.py\r\n‚îú‚îÄ bulk_upload_utils.py     ‚Üê NEW (helper)\r\n‚îî‚îÄ pages/\r\n   ‚îú‚îÄ 1_Home.py\r\n   ‚îú‚îÄ 2_Visualization.py\r\n   ‚îú‚îÄ 3_Data_View.py\r\n   ‚îú‚îÄ 4_Quick_Profile.py\r\n   ‚îî‚îÄ 5_Bulk_Upload_CSV.py  ‚Üê UPDATED (uses helper)</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REQUIREMENTS -->\r\n    <section class=\"section-card\" id=\"reqs\">\r\n      <div class=\"banner\">\r\n        <small>Dependencies</small>\r\n        <h1>requirements.txt (no extras needed)</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>streamlit\r\npandas\r\nnumpy</pre>\r\n        <p>These pages don't require Altair. (Your Quick Profile page does.)</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- HELPER: bulk_upload_utils.py -->\r\n    <section class=\"section-card\" id=\"helper\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>bulk_upload_utils.py</h1>\r\n        <p>Reusable utilities: normalize headers, read CSVs, align schemas, safe appends, diagnostics</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># bulk_upload_utils.py\r\nfrom __future__ import annotations\r\n\r\nimport io\r\nfrom pathlib import Path\r\nfrom typing import Iterable, List, Optional, Tuple\r\n\r\nimport pandas as pd\r\nimport streamlit as st\r\n\r\n\r\n# ---------- Column utilities ----------\r\ndef standardize_cols(\r\n    cols: Iterable[str],\r\n    *,\r\n    case: str = \"keep\",         # keep | lower | upper\r\n    trim: bool = True,\r\n    spaces: str = \"keep\",       # keep | single | underscore\r\n) -> List[str]:\r\n    out: List[str] = []\r\n    for c in cols:\r\n        name = str(c)\r\n        if trim:\r\n            name = name.strip()\r\n        if spaces == \"single\":\r\n            name = \" \".join(name.split())\r\n        elif spaces == \"underscore\":\r\n            name = \"_\".join(name.split())\r\n        if case == \"lower\":\r\n            name = name.lower()\r\n        elif case == \"upper\":\r\n            name = name.upper()\r\n        out.append(name)\r\n    return out\r\n\r\n\r\ndef coerce_common_datetime_cols(df: pd.DataFrame) -> pd.DataFrame:\r\n    \"\"\"Coerce columns named like dates into datetime (non-fatal).\"\"\"\r\n    for col in df.columns:\r\n        name = str(col).lower()\r\n        if name in (\"date\", \"time\", \"timestamp\", \"datetime\"):\r\n            df[col] = pd.to_datetime(df[col], errors=\"coerce\")\r\n    return df\r\n\r\n\r\ndef format_datetime_cols_for_write(\r\n    df: pd.DataFrame,\r\n    *,\r\n    mode: str = \"date\",  # date | iso | keep\r\n) -> pd.DataFrame:\r\n    \"\"\"Optionally format datetime-like columns before writing to CSV.\"\"\"\r\n    if mode == \"keep\":\r\n        return df\r\n    out = df.copy()\r\n    for c in out.columns:\r\n        if pd.api.types.is_datetime64_any_dtype(out[c]):\r\n            if mode == \"date\":\r\n                out[c] = out[c].dt.date.astype(\"string\")\r\n            elif mode == \"iso\":\r\n                out[c] = out[c].dt.strftime(\"%Y-%m-%dT%H:%M:%S\").astype(\"string\")\r\n    return out\r\n\r\n\r\ndef infer_numeric(df: pd.DataFrame, columns: Optional[List[str]] = None) -> pd.DataFrame:\r\n    cols = columns or df.columns.tolist()\r\n    out = df.copy()\r\n    for c in cols:\r\n        if out[c].dtype == \"object\":\r\n            out[c] = pd.to_numeric(out[c].astype(str).str.replace(\",\", \"\", regex=False), errors=\"ignore\")\r\n    return out\r\n\r\n\r\n# ---------- Reading ----------\r\n@st.cache_data(show_spinner=False)\r\ndef read_one_csv(\r\n    content: bytes,\r\n    *,\r\n    encoding: str = \"utf-8\",\r\n    sep_choice: str = \"Auto (sniff)\",  # Auto (sniff) | Comma (,) | Semicolon (;) | Tab (\\t)\r\n    decimal: str = \".\",\r\n    header_row: bool = True,\r\n    treat_empty_as_na: bool = True,\r\n    parse_dates_auto: bool = True,\r\n) -> pd.DataFrame:\r\n    \"\"\"Read a CSV from bytes with flexible options.\"\"\"\r\n    bio = io.BytesIO(content)\r\n    if sep_choice == \"Auto (sniff)\":\r\n        sep, engine = None, \"python\"  # python engine for sep=None sniffing\r\n    elif sep_choice == \"Comma (,)\":\r\n        sep, engine = \",\", None\r\n    elif sep_choice == \"Semicolon (;)\":\r\n        sep, engine = \";\", None\r\n    else:\r\n        sep, engine = \"\\t\", None  # Tab\r\n\r\n    na_vals = None\r\n    keep_default_na = True\r\n    if treat_empty_as_na:\r\n        na_vals = [\"\", \"NA\", \"N/A\", \"na\", \"n/a\", \"NULL\", \"null\", \"None\", \"none\"]\r\n\r\n    df = pd.read_csv(\r\n        bio,\r\n        encoding=encoding,\r\n        sep=sep,\r\n        engine=engine,\r\n        header=0 if header_row else None,\r\n        decimal=decimal,\r\n        na_values=na_vals,\r\n        keep_default_na=keep_default_na,\r\n    )\r\n    if not header_row:\r\n        df.columns = [f\"col_{i+1}\" for i in range(df.shape[1])]\r\n    if parse_dates_auto:\r\n        df = coerce_common_datetime_cols(df)\r\n    return df\r\n\r\n\r\n# ---------- Base CSV schema / dedupe ----------\r\ndef read_base_columns(path: Path) -> Optional[List[str]]:\r\n    if not path.exists() or path.stat().st_size == 0:\r\n        return None\r\n    try:\r\n        return pd.read_csv(path, nrows=0).columns.tolist()\r\n    except Exception as e:\r\n        st.error(f\"Couldn't read base CSV header at {path}: {e}\")\r\n        return None\r\n\r\n\r\ndef align_to_base(df: pd.DataFrame, base_cols: List[str]) -> pd.DataFrame:\r\n    out = df.copy()\r\n    for c in base_cols:\r\n        if c not in out.columns:\r\n            out[c] = pd.NA\r\n    return out[base_cols]\r\n\r\n\r\ndef anti_join_vs_base(\r\n    new_df: pd.DataFrame,\r\n    base_path: Path,\r\n    keys: List[str],\r\n) -> Tuple[pd.DataFrame, int]:\r\n    \"\"\"Remove rows from new_df that already exist in base (by keys).\"\"\"\r\n    try:\r\n        base_subset = pd.read_csv(base_path, usecols=keys, dtype=str).astype(str)\r\n    except ValueError:\r\n        # Missing cols in base; can't compare\r\n        return new_df, 0\r\n    except Exception as e:\r\n        st.warning(f\"Could not read base for dedupe: {e}\")\r\n        return new_df, 0\r\n\r\n    left = new_df[keys].astype(str)\r\n    left[\"_k\"] = left.apply(lambda r: \"¬ß\".join(r.values.tolist()), axis=1)\r\n    base_subset[\"_k\"] = base_subset.apply(lambda r: \"¬ß\".join(r.values.tolist()), axis=1)\r\n    keep_mask = ~left[\"_k\"].isin(base_subset[\"_k\"])\r\n    removed = int((~keep_mask).sum())\r\n    return new_df.loc[keep_mask].copy(), removed\r\n\r\n\r\n# ---------- Safe appends ----------\r\ndef last_byte_is_newline(path: Path) -> Optional[bool]:\r\n    if not path.exists() or path.stat().st_size == 0:\r\n        return None\r\n    with path.open(\"rb\") as f:\r\n        f.seek(-1, 2)\r\n        return f.read(1) == b\"\\n\"\r\n\r\n\r\ndef ensure_trailing_newline(path: Path) -> None:\r\n    \"\"\"If file exists and doesn't end with '\\n', append one.\"\"\"\r\n    lb = last_byte_is_newline(path)\r\n    if lb is False:\r\n        with path.open(\"ab\") as f:\r\n            f.write(b\"\\n\")\r\n\r\n\r\ndef safe_append_csv(path: Path, df: pd.DataFrame) -> None:\r\n    \"\"\"Append rows ensuring newline boundary & consistent line endings.\"\"\"\r\n    if df.empty:\r\n        return\r\n    if path.exists() and path.stat().st_size > 0:\r\n        ensure_trailing_newline(path)\r\n        df.to_csv(path, mode=\"a\", header=False, index=False, encoding=\"utf-8\", lineterminator=\"\\n\")\r\n    else:\r\n        df.to_csv(path, mode=\"w\", header=True, index=False, encoding=\"utf-8\", lineterminator=\"\\n\")\r\n\r\n\r\n# ---------- File introspection ----------\r\ndef tail_lines(path: Path, n: int = 5) -> List[str]:\r\n    \"\"\"Read the last n lines of a text file safely (UTF-8 assumed).\"\"\"\r\n    if not path.exists() or path.stat().st_size == 0:\r\n        return []\r\n    with path.open(\"rb\") as f:\r\n        f.seek(0, 2)\r\n        size = f.tell()\r\n        block = 1024\r\n        data = b\"\"\r\n        while len(data.splitlines()) <= n and f.tell() > 0:\r\n            step = min(block, f.tell())\r\n            f.seek(-step, 1)\r\n            data = f.read(step) + data\r\n            f.seek(-step, 1)\r\n        lines = data.splitlines()[-n:]\r\n    return [ln.decode(\"utf-8\", errors=\"replace\") for ln in lines]\r\n\r\n\r\ndef count_rows_fast(path: Path) -> Optional[int]:\r\n    \"\"\"Count data rows quickly (excludes header).\"\"\"\r\n    if not path.exists() or path.stat().st_size == 0:\r\n        return 0\r\n    try:\r\n        with path.open(\"rb\") as f:\r\n            n = 0\r\n            for n, _ in enumerate(f, start=1):\r\n                pass\r\n        return max(0, n - 1)\r\n    except Exception:\r\n        return None\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- PAGE: 5_Bulk_Upload_CSV.py (updated) -->\r\n    <section class=\"section-card\" id=\"page\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>pages/5_Bulk_Upload_CSV.py</h1>\r\n        <p>Now imports helpers for safety, clarity, and reuse</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># pages/5_Bulk_Upload_CSV.py\r\nfrom __future__ import annotations\r\n\r\nfrom pathlib import Path\r\nfrom typing import List, Tuple\r\n\r\nimport pandas as pd\r\nimport streamlit as st\r\n\r\nfrom bulk_upload_utils import (\r\n    align_to_base,\r\n    anti_join_vs_base,\r\n    coerce_common_datetime_cols,\r\n    count_rows_fast,\r\n    ensure_trailing_newline,\r\n    format_datetime_cols_for_write,\r\n    infer_numeric,\r\n    last_byte_is_newline,\r\n    read_base_columns,\r\n    read_one_csv,\r\n    safe_append_csv,\r\n    standardize_cols,\r\n    tail_lines,\r\n)\r\n\r\nst.title(\"üì§ Bulk CSV Upload ‚Üí Append to Base File (safe & helper-backed)\")\r\nst.caption(\"Combine multiple CSVs and append them to /workspaces/photos/data/weather.csv without line merges.\")\r\n\r\n# -----------------------------\r\n# Constants\r\n# -----------------------------\r\nBASE_CSV_PATH = Path(\"/workspaces/photos/data/weather.csv\")\r\nBASE_CSV_PATH.parent.mkdir(parents=True, exist_ok=True)  # ensure folder exists\r\n\r\n# -----------------------------\r\n# Sidebar\r\n# -----------------------------\r\nwith st.sidebar:\r\n    st.header(\"Upload\")\r\n    files = st.file_uploader(\"Choose one or more CSV files\", type=[\"csv\"], accept_multiple_files=True)\r\n\r\n    st.header(\"Read Options\")\r\n    encoding = st.selectbox(\"Encoding\", [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\"], index=0)\r\n    sep_choice = st.selectbox(\"Delimiter\", [\"Auto (sniff)\", \"Comma (,)\", \"Semicolon (;)\", \"Tab (\\\\t)\"], index=0)\r\n    decimal = st.selectbox(\"Decimal marker\", [\".\", \",\"], index=0)\r\n    header_row = st.checkbox(\"First row is header\", value=True)\r\n    treat_empty_as_na = st.checkbox(\"Treat empty strings as missing\", value=True)\r\n    parse_dates_auto = st.checkbox(\"Auto-parse common date/time columns\", value=True)\r\n\r\n    st.header(\"Standardize Columns\")\r\n    col_case = st.selectbox(\"Case\", [\"keep\", \"lower\", \"upper\"], index=0)\r\n    col_trim = st.checkbox(\"Trim whitespace\", value=True)\r\n    col_spaces = st.selectbox(\"Spaces\", [\"keep\", \"single\", \"underscore\"], index=0)\r\n    add_source = st.checkbox(\"Add source filename column\", value=False)\r\n    source_col_name = st.text_input(\"Source column name\", value=\"source_file\", disabled=not add_source)\r\n\r\n    st.header(\"Combine Mode\")\r\n    union_mode = st.radio(\"How to combine columns\", [\"Union by name (outer)\", \"Only common columns (inner)\"], index=0)\r\n\r\n    st.header(\"Post-processing\")\r\n    try_infer_numeric = st.checkbox(\"Try to convert numeric-looking text\", value=True)\r\n    drop_empty_cols = st.checkbox(\"Drop all-empty columns\", value=True)\r\n    dt_write_mode = st.selectbox(\"Format datetimes on write\", [\"date\", \"iso\", \"keep\"], index=0)\r\n\r\n    st.header(\"Deduplicate (within upload)\")\r\n    dedup_mode = st.radio(\"Remove duplicates\", [\"No\", \"Across all columns\", \"Choose columns\"], index=0)\r\n\r\n    st.header(\"Append Control\")\r\n    dry_run = st.checkbox(\"Dry run (preview only, don't write)\", value=False)\r\n\r\n    st.header(\"Cache\")\r\n    if st.button(\"Clear cache\"):\r\n        st.cache_data.clear()\r\n        st.success(\"Cache cleared.\")\r\n\r\n# -----------------------------\r\n# Step 1: Read all files\r\n# -----------------------------\r\nif not files:\r\n    st.info(\"Upload one or more CSV files to start.\")\r\n    st.stop()\r\n\r\nst.subheader(\"Step 1 ‚Äî File Summary\")\r\n\r\ndfs: List[pd.DataFrame] = []\r\nmeta: List[Tuple[str, int, int]] = []\r\n\r\nprogress = st.progress(0.0)\r\nfor i, f in enumerate(files, start=1):\r\n    df_i = read_one_csv(\r\n        f.getvalue(),\r\n        encoding=encoding,\r\n        sep_choice=sep_choice,\r\n        decimal=decimal,\r\n        header_row=header_row,\r\n        treat_empty_as_na=treat_empty_as_na,\r\n        parse_dates_auto=parse_dates_auto,\r\n    )\r\n    df_i.columns = standardize_cols(df_i.columns, case=col_case, trim=col_trim, spaces=col_spaces)\r\n    if add_source:\r\n        df_i[source_col_name] = f.name\r\n    if try_infer_numeric:\r\n        df_i = infer_numeric(df_i)\r\n    if drop_empty_cols:\r\n        df_i = df_i.dropna(axis=1, how=\"all\")\r\n\r\n    dfs.append(df_i)\r\n    meta.append((f.name, df_i.shape[0], df_i.shape[1]))\r\n    progress.progress(i / len(files))\r\nprogress.empty()\r\n\r\nst.dataframe(pd.DataFrame(meta, columns=[\"file\", \"rows\", \"cols\"]), width=\"stretch\")\r\n\r\nwith st.expander(\"Preview first rows of each file\"):\r\n    for f, df_i in zip(files, dfs):\r\n        st.markdown(f\"**{f.name}** ‚Äî {len(df_i):,} rows √ó {len(df_i.columns)} cols\")\r\n        st.dataframe(df_i.head(10), width=\"stretch\")\r\n\r\n# -----------------------------\r\n# Step 2: Combine uploads\r\n# -----------------------------\r\nst.subheader(\"Step 2 ‚Äî Combine\")\r\njoin_how = \"outer\" if union_mode.startswith(\"Union\") else \"inner\"\r\n\r\nif join_how == \"outer\":\r\n    ordered_cols: List[str] = []\r\n    seen = set()\r\n    for df_i in dfs:\r\n        for c in df_i.columns:\r\n            if c not in seen:\r\n                seen.add(c)\r\n                ordered_cols.append(c)\r\nelse:\r\n    common = set(dfs[0].columns)\r\n    for df_i in dfs[1:]:\r\n        common &= set(df_i.columns)\r\n    ordered_cols = [c for c in dfs[0].columns if c in common]\r\n\r\nif not ordered_cols:\r\n    st.error(\"No overlapping columns to combine. Adjust standardization or use union mode.\")\r\n    st.stop()\r\n\r\ncombined = pd.concat(\r\n    [d[ordered_cols] if join_how == \"inner\" else d.reindex(columns=ordered_cols) for d in dfs],\r\n    axis=0,\r\n    ignore_index=True,\r\n)\r\n\r\n# Within-upload dedupe\r\nbefore_rows = combined.shape[0]\r\nremoved_within = 0\r\nif dedup_mode == \"Across all columns\":\r\n    combined = combined.drop_duplicates()\r\n    removed_within = before_rows - combined.shape[0]\r\nelif dedup_mode == \"Choose columns\":\r\n    chosen = st.multiselect(\"Deduplicate on columns\", options=ordered_cols, default=ordered_cols)\r\n    if chosen:\r\n        combined = combined.drop_duplicates(subset=chosen)\r\n        removed_within = before_rows - combined.shape[0]\r\nif removed_within:\r\n    st.success(f\"Removed {removed_within:,} duplicate rows within the uploaded data.\")\r\n\r\nst.markdown(\"**Combined preview**\")\r\nst.dataframe(combined.head(100), width=\"stretch\")\r\n\r\n# -----------------------------\r\n# Step 3: Append to base CSV (with helper safety)\r\n# -----------------------------\r\nst.subheader(\"Step 3 ‚Äî Append to Base CSV\")\r\nst.caption(f\"Base file path: `{BASE_CSV_PATH}`\")\r\n\r\n# Base stats and tail preview\r\nbase_cols = read_base_columns(BASE_CSV_PATH)\r\nrows_in_base = count_rows_fast(BASE_CSV_PATH)\r\nlb = last_byte_is_newline(BASE_CSV_PATH)\r\ncol1, col2, col3 = st.columns(3)\r\ncol1.metric(\"Rows in base\", \"‚Äî\" if rows_in_base is None else f\"{rows_in_base:,}\")\r\ncol2.metric(\"Has trailing newline\", \"N/A\" if lb is None else (\"Yes\" if lb else \"No\"))\r\ncol3.metric(\"Base exists\", \"Yes\" if base_cols is not None else \"No (will create)\")\r\n\r\nif base_cols:\r\n    st.markdown(\"**Base CSV schema (in order):**\")\r\n    st.code(\", \".join(base_cols), language=\"text\")\r\n    with st.expander(\"Tail of base file (last 5 lines)\"):\r\n        for ln in tail_lines(BASE_CSV_PATH, 5):\r\n            st.text(ln)\r\n\r\n# Align & optional dedupe vs base\r\nif base_cols is None:\r\n    st.warning(\"Base CSV does not exist or is empty. Appending will CREATE it using the combined upload's columns.\")\r\n    to_write = format_datetime_cols_for_write(combined, mode=dt_write_mode)\r\n    st.code(\", \".join(to_write.columns), language=\"text\")\r\nelse:\r\n    aligned = align_to_base(combined, base_cols)\r\n    to_write = format_datetime_cols_for_write(aligned, mode=dt_write_mode)\r\n\r\n    st.markdown(\"**Preview of rows to append (aligned):**\")\r\n    st.dataframe(to_write.head(30), width=\"stretch\")\r\n\r\n    # Optional dedupe vs base\r\n    st.markdown(\"**Duplicate check vs base (optional)**\")\r\n    dedupe_vs_base = st.radio(\r\n        \"Avoid adding rows that already exist in the base (match by):\",\r\n        [\"Off\", \"All base columns\", \"Choose columns\"],\r\n        index=0,\r\n        horizontal=True,\r\n    )\r\n    if dedupe_vs_base != \"Off\":\r\n        if dedupe_vs_base == \"All base columns\":\r\n            keys = base_cols\r\n        else:\r\n            keys = st.multiselect(\"Columns to match\", options=base_cols, default=base_cols)\r\n        if keys:\r\n            to_write, removed_vs_base = anti_join_vs_base(to_write, BASE_CSV_PATH, keys)\r\n            if removed_vs_base:\r\n                st.success(f\"Skipped {removed_vs_base:,} rows already present in base.\")\r\n\r\n# Action buttons\r\ncolA, colB = st.columns(2)\r\nif dry_run:\r\n    colA.info(f\"Dry run active ‚Äî would append {len(to_write):,} rows. No changes will be written.\")\r\nelse:\r\n    write_btn = colA.button(f\"Append {len(to_write):,} rows to base CSV\")\r\n    if write_btn:\r\n        try:\r\n            safe_append_csv(BASE_CSV_PATH, to_write)\r\n            st.success(f\"Appended {len(to_write):,} rows to `{BASE_CSV_PATH}` safely.\")\r\n            st.toast(\"Append complete\", icon=\"‚úÖ\")\r\n            st.caption(\"If other pages still show old data, use their sidebar ‚Üí Clear cache.\")\r\n        except Exception as e:\r\n            st.error(f\"Failed to append to base CSV: {e}\")\r\n\r\n# Optional: manual newline fix (rarely needed now)\r\nif lb is False:\r\n    if colB.button(\"Fix trailing newline now\"):\r\n        try:\r\n            ensure_trailing_newline(BASE_CSV_PATH)\r\n            st.success(\"Added trailing newline to base file.\")\r\n        except Exception as e:\r\n            st.error(f\"Failed to add trailing newline: {e}\")\r\n\r\n# -----------------------------\r\n# Optional download\r\n# -----------------------------\r\nst.subheader(\"Optional ‚Äî Download Combined Upload\")\r\nst.download_button(\r\n    \"‚¨áÔ∏è Download combined CSV\",\r\n    data=combined.to_csv(index=False).encode(\"utf-8\"),\r\n    file_name=\"combined_upload.csv\",\r\n    mime=\"text/csv\",\r\n)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- RUN -->\r\n    <section class=\"section-card\" id=\"run\">\r\n      <div class=\"banner\">\r\n        <small>Run</small>\r\n        <h1>Run in Codespaces</h1>\r\n        <p>Install ‚Üí Run ‚Üí Open Port</p>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>pip install -r requirements.txt\r\nstreamlit run app.py --server.address 0.0.0.0 --server.port 8000</pre>\r\n        <p>Open the forwarded port (8000). In the sidebar you'll now see <strong>\"5_Bulk_Upload_CSV\"</strong>.</p>\r\n        <p><em>Note:</em> The script writes to <span class=\"inline\">/workspaces/photos/data/weather.csv</span>. The folder is created if missing.</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n  (function(){\r\n    const now = new Date();\r\n    document.getElementById('y').textContent = now.getFullYear();\r\n    document.getElementById('d').textContent = now.toLocaleDateString(\r\n      undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n    );\r\n  })();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "8ec8fced-f5ef-40f5-a2d7-1977417eda4d"
    },
    {
      "kind": "article",
      "order": 6,
      "title": "The One-Thing Improvement Loop",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Modularity Tips ‚Ä¢ The One-Thing Improvement Loop</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 900px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Grid & code === */\r\n.quick-grid { display: grid; grid-template-columns: 1fr; gap: 14px; margin-top: 12px; }\r\n.box { border: 1px solid #EBEBEB; border-radius: 10px; padding: 14px; background: #fafafa; }\r\n.box h3 { margin: 0 0 6px; font-size: 17px; color: #000; }\r\n.box p { margin: 0; }\r\n\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\nul { margin: 0; padding-left: 18px; }\r\nli + li { margin-top: 6px; }\r\n\r\n/* === Footer note === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n\r\n/* Responsive */\r\n@media (min-width: 720px) { .quick-grid { grid-template-columns: repeat(2, 1fr); } }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Modularity</small>\r\n        <h1>The ‚ÄúOne-Thing‚Äù Improvement Loop</h1>\r\n        <p>Make one change. Ship. Repeat ‚Äî endlessly and safely.</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          A simple habit drives continuous improvement: ask your assistant to do **one specific upgrade** to your script,\r\n          re-write it end-to-end, and repeat. Because changes are modular and focused, quality rises without chaos.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- THE PROMPT PATTERN -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Pattern</small>\r\n        <h1>The Core Prompt</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>Start with one aspect (e.g., speed, UI, UX, reliability) and ask for a single change:</p>\r\n<pre>\"Do one thing that makes the 'speed' of my script better. Write the script from A to Z.\"</pre>\r\n        <p>Then, loop it with positive reinforcement:</p>\r\n<pre>\"Well done, do one thing that makes the 'speed' of my script better. Write it again from A to Z.\"</pre>\r\n        <p><strong>Why this works:</strong> it adds exactly one improvement each cycle, keeping scope small and momentum high.</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- ASPECTS YOU CAN TARGET -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Aspects</small>\r\n        <h1>What You Can Improve ‚Äî One at a Time</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <div class=\"quick-grid\">\r\n          <div class=\"box\">\r\n            <h3>Speed / Performance</h3>\r\n            <p>Vectorized ops, caching, I/O batching, lazy loads, algorithmic tweaks.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>User Interface</h3>\r\n            <p>Cleaner layout, consistent spacing, better labels/placeholders, responsive cards.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>User Experience</h3>\r\n            <p>Safer defaults, undo/confirm flows, progress & toasts, sensible empty states.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>Reliability</h3>\r\n            <p>Error handling, retries with backoff, input validation, schema checks.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>Security</h3>\r\n            <p>Sanitize inputs, secrets handling, least privilege, dependency pins.</p>\r\n          </div>\r\n          <div class=\"box\">\r\n            <h3>Maintainability</h3>\r\n            <p>Split into modules, docstrings, type hints, linting, tests.</p>\r\n          </div>\r\n        </div>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- LOOP WORKFLOW -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Workflow</small>\r\n        <h1>How to Run the Never-Ending Loop</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <ol>\r\n          <li><strong>Pick one aspect.</strong> E.g., ‚Äúspeed‚Äù.</li>\r\n          <li><strong>Run the core prompt.</strong> Get a full rewritten script.</li>\r\n          <li><strong>Test locally.</strong> Run unit checks or a quick manual run (Streamlit/Codespace).</li>\r\n          <li><strong>Commit & push.</strong> One improvement = one commit.</li>\r\n          <li><strong>Repeat.</strong> Ask for the next ‚Äúone thing‚Äù on the same aspect or switch to a new one.</li>\r\n        </ol>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- READY PROMPTS -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Templates</small>\r\n        <h1>Copy-Paste Prompts</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p><strong>Performance:</strong></p>\r\n<pre>\"Do one thing that makes the 'speed' of my script better. Write the script from A to Z.\"</pre>\r\n        <p><strong>User Interface:</strong></p>\r\n<pre>\"Do one thing that makes the 'user interface' clearer and more consistent. Write the script from A to Z.\"</pre>\r\n        <p><strong>User Experience:</strong></p>\r\n<pre>\"Do one thing that improves the 'user experience' and reduces friction. Write the script from A to Z.\"</pre>\r\n        <p><strong>Reliability:</strong></p>\r\n<pre>\"Do one thing that improves 'reliability' and error handling. Write the script from A to Z.\"</pre>\r\n        <p><strong>Maintainability:</strong></p>\r\n<pre>\"Do one thing that improves 'modularity and readability' without changing behavior. Write the script from A to Z.\"</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- GUARDRAILS -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Guardrails</small>\r\n        <h1>Make It Safe & Effective</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <ul>\r\n          <li><strong>One change only.</strong> If the model adds many tweaks, ask it to limit to exactly one.</li>\r\n          <li><strong>Keep behavior.</strong> For refactors, say ‚Äúno behavior changes unless necessary.‚Äù</li>\r\n          <li><strong>Measure.</strong> For speed, include a quick timing or profile note to verify the win.</li>\r\n          <li><strong>Version control.</strong> Commit each improvement separately; easy rollbacks.</li>\r\n          <li><strong>Stay modular.</strong> Prefer helper modules (e.g., <span class=\"inline\">lib_data.py</span> or <span class=\"inline\">bulk_upload_utils.py</span>) for shared changes.</li>\r\n        </ul>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- WHY IT WORKS -->\r\n    <section class=\"section-card\">\r\n      <div class=\"banner\">\r\n        <small>Why</small>\r\n        <h1>Why the Never-Ending Prompt Works</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <ul>\r\n          <li><strong>Focus:</strong> One clear goal prevents scope creep.</li>\r\n          <li><strong>Momentum:</strong> Small wins stack quickly into big gains.</li>\r\n          <li><strong>Safety:</strong> Each change is easy to test and revert.</li>\r\n          <li><strong>Modularity:</strong> Encourages clean separations and helper libraries.</li>\r\n        </ul>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n(function(){\r\n  const now = new Date();\r\n  document.getElementById('y').textContent = now.getFullYear();\r\n  document.getElementById('d').textContent = now.toLocaleDateString(\r\n    undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n  );\r\n})();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "e3d4a1ad-3c66-4055-bd27-f2eee2e8b24f"
    },
    {
      "kind": "article",
      "order": 7,
      "title": "Repo Analyzer Script",
      "content": {
        "body_md": "<!DOCTYPE html>\r\n<html lang=\"en\">\r\n<head>\r\n<meta charset=\"utf-8\" />\r\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\r\n<title>Codex-Level Modularity Tips ‚Ä¢ Repo Analyzer Script</title>\r\n\r\n<style>\r\n/* === Global resets === */\r\n* { box-sizing: border-box; word-wrap: break-word; overflow-wrap: break-word; }\r\nbody { font: 16px/1.55 system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; color: #555; margin: 0; background: #fff; }\r\n\r\n/* === Page wrap === */\r\n.wrap { max-width: 1000px; margin: 0 auto; padding: 18px; }\r\n\r\n/* === Video container === */\r\n.video-container {\r\n  margin-bottom: 32px;\r\n  border-radius: 12px;\r\n  overflow: hidden;\r\n  box-shadow: 0 4px 12px rgba(0,0,0,0.1);\r\n  background: #f8f9fa;\r\n  padding: 16px;\r\n}\r\n\r\n.video-container iframe {\r\n  width: 100%;\r\n  height: auto;\r\n  aspect-ratio: 16/9;\r\n  border-radius: 8px;\r\n}\r\n\r\n/* === Card container === */\r\n.section-card {\r\n  border: 1px solid #EBEBEB; border-radius: 14px; overflow: hidden;\r\n  box-shadow: 0 1px 2px rgba(0,0,0,.04); margin-bottom: 24px; background: #ffffff;\r\n}\r\n\r\n/* === Banner / header === */\r\n.section-card .banner { background: linear-gradient(120deg, #555555, #000000); color: #FFFFFF; padding: 18px 20px; }\r\n.section-card .banner small { font-size: 12px; letter-spacing: .08em; opacity: .9; text-transform: uppercase; color: #FFFFFF; }\r\n.section-card .banner h1 { margin: 6px 0 4px; font-size: 24px; line-height: 1.2; color: #FFFFFF; }\r\n.section-card .banner p { margin: 0; opacity: .95; color: #FFFFFF; }\r\n\r\n/* === Body === */\r\n.section-card .body { padding: 20px; }\r\n.section-card p { font-size: 16px; margin-top: 0; color: #555; }\r\n\r\n/* === Code blocks === */\r\npre {\r\n  background: #1e1e1e; color: #f3f3f3;\r\n  padding: 14px; border-radius: 10px; overflow-x: auto;\r\n  font-family: Consolas, Monaco, ui-monospace, SFMono-Regular, Menlo, monospace; font-size: 14px;\r\n}\r\n.inline { background: #f0f0f0; border-radius: 4px; padding: 2px 6px; font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }\r\n\r\nul { margin: 0; padding-left: 18px; }\r\nli + li { margin-top: 6px; }\r\n\r\n/* === Footer === */\r\n.footer-note { font-size: 13px; color: #777; text-align: center; margin: 30px 0 10px; }\r\n</style>\r\n</head>\r\n<body>\r\n  <div class=\"wrap\">\r\n\r\n    <!-- VIDEO SECTION -->\r\n    <div class=\"video-container\">\r\n      <iframe width=\"1047\" height=\"473\" src=\"https://www.youtube.com/embed/A9LEplNTmMI\" title=\"Repo Analyzer Script\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\r\n    </div>\r\n\r\n    <!-- INTRO -->\r\n    <section class=\"section-card\" id=\"intro\">\r\n      <div class=\"banner\">\r\n        <small>Codex-Level</small>\r\n        <h1>Modularity Tips + Whole-Repo Analyzer</h1>\r\n        <p>Diagnose functions, complexity, typing, imports, and anti-patterns across your codebase</p>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>\r\n          When a project grows, modularity isn't just about splitting files ‚Äî it's about **continuous diagnostics**.\r\n          Drop the analyzer below at your repo root and run it whenever you need a quick health check or refactor plan.\r\n        </p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- WHY / WHAT IT CHECKS -->\r\n    <section class=\"section-card\" id=\"why\">\r\n      <div class=\"banner\">\r\n        <small>Why</small>\r\n        <h1>What This Analyzer Catches</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <ul>\r\n          <li><strong>Function inventory:</strong> names, args, length (LOC), missing docstrings, missing type hints.</li>\r\n          <li><strong>Complexity signals:</strong> naive cyclomatic score (ifs/loops/try/and/or/comprehensions).</li>\r\n          <li><strong>Anti-patterns:</strong> broad <span class=\"inline\">except:</span>, nested functions, very long functions.</li>\r\n          <li><strong>Imports:</strong> stdlib vs third-party vs local; quick scan for unused (best-effort).</li>\r\n          <li><strong>Hygiene:</strong> <span class=\"inline\">TODO/FIXME</span> markers, trailing whitespace, mixed tabs/spaces.</li>\r\n          <li><strong>Project view:</strong> per-file summaries + top offenders list to guide your next \"one-thing\" fix.</li>\r\n        </ul>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- REPO LAYOUT -->\r\n    <section class=\"section-card\" id=\"layout\">\r\n      <div class=\"banner\">\r\n        <small>Layout</small>\r\n        <h1>Where This Fits</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre>.\r\n‚îú‚îÄ app.py\r\n‚îú‚îÄ lib_data.py\r\n‚îú‚îÄ bulk_upload_utils.py\r\n‚îú‚îÄ pages/\r\n‚îÇ  ‚îú‚îÄ 1_Home.py\r\n‚îÇ  ‚îú‚îÄ 2_Visualization.py\r\n‚îÇ  ‚îú‚îÄ 3_Data_View.py\r\n‚îÇ  ‚îú‚îÄ 4_Quick_Profile.py\r\n‚îÇ  ‚îî‚îÄ 5_Bulk_Upload_CSV.py\r\n‚îî‚îÄ analyze_repo.py   <‚Äî NEW (run from repo root)\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- SCRIPT -->\r\n    <section class=\"section-card\" id=\"script\">\r\n      <div class=\"banner\">\r\n        <small>Code</small>\r\n        <h1>analyze_repo.py (Standard-Library Only)</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># analyze_repo.py\r\nimport ast\r\nimport json\r\nimport re\r\nimport sys\r\nfrom dataclasses import dataclass, asdict\r\nfrom pathlib import Path\r\nfrom typing import List, Dict, Optional, Tuple\r\n\r\nEXCLUDE_DIRS = {\".git\", \".venv\", \"venv\", \"__pycache__\", \".mypy_cache\", \".pytest_cache\", \".idea\", \".vscode\"}\r\nPY_EXT = {\".py\"}\r\n\r\n# --- heuristics ---\r\nLONG_FUNC_LOC = 60\r\nHIGH_COMPLEXITY = 10  # naive cyclomatic threshold\r\n\r\nBRANCH_NODES = (ast.If, ast.For, ast.While, ast.Try, ast.With, ast.BoolOp, ast.IfExp, ast.ExceptHandler, ast.comprehension)\r\n\r\n@dataclass\r\nclass FuncReport:\r\n  name: str\r\n  lineno: int\r\n  loc: int\r\n  args: List[str]\r\n  has_doc: bool\r\n  typed_args: bool\r\n  typed_ret: bool\r\n  complexity: int\r\n  nested: bool\r\n  broad_except: bool\r\n\r\n@dataclass\r\nclass FileReport:\r\n  path: str\r\n  functions: List[FuncReport]\r\n  imports: Dict[str, List[str]]  # {\"stdlib\":[], \"thirdparty\":[], \"local\":[]}\r\n  todos: int\r\n  mixed_ws: bool\r\n  trailing_ws: bool\r\n  long_funcs: int\r\n  high_complexity_funcs: int\r\n\r\ndef is_stdlib_module(mod: str) -> bool:\r\n  # Heuristic: builtins + common stdlib modules (fast, no imports)\r\n  COMMON_STDLIB = {\r\n    \"os\",\"sys\",\"re\",\"json\",\"pathlib\",\"typing\",\"dataclasses\",\"functools\",\"itertools\",\"collections\",\r\n    \"subprocess\",\"datetime\",\"time\",\"math\",\"random\",\"logging\",\"argparse\",\"shutil\",\"tempfile\",\"hashlib\",\r\n    \"http\",\"urllib\",\"unittest\",\"asyncio\",\"enum\",\"inspect\",\"traceback\",\"gzip\",\"csv\",\"io\",\"zipfile\"\r\n  }\r\n  base = (mod or \"\").split(\".\")[0]\r\n  return base in COMMON_STDLIB\r\n\r\ndef guess_import_kind(name: str, file_path: Path) -> str:\r\n  # local: relative imports or top-level package present in repo\r\n  if name.startswith(\".\"):\r\n    return \"local\"\r\n  if is_stdlib_module(name):\r\n    return \"stdlib\"\r\n  # very rough: if there's a sibling dir/file named like the import -> local\r\n  root = file_path.parent\r\n  if (root / name).exists() or (root / (name + \".py\")).exists():\r\n    return \"local\"\r\n  return \"thirdparty\"\r\n\r\ndef naive_complexity(node: ast.AST) -> int:\r\n  score = 1\r\n  for n in ast.walk(node):\r\n    if isinstance(n, BRANCH_NODES):\r\n      score += 1\r\n    if isinstance(n, ast.BoolOp):\r\n      score += max(0, len(n.values) - 1)\r\n  return score\r\n\r\ndef func_loc(src: str, node: ast.AST) -> int:\r\n  try:\r\n    # Python 3.8+ nodes often have end_lineno\r\n    end = getattr(node, \"end_lineno\", node.lineno)\r\n    return max(1, end - node.lineno + 1)\r\n  except Exception:\r\n    return 1\r\n\r\ndef has_type_hints(func: ast.FunctionDef) -> Tuple[bool,bool]:\r\n  typed_args = any(a.annotation is not None for a in func.args.args + func.args.kwonlyargs) or \\\r\n               (func.args.vararg and func.args.vararg.annotation is not None) or \\\r\n               (func.args.kwarg and func.args.kwarg.annotation is not None)\r\n  typed_ret = func.returns is not None\r\n  return typed_args, typed_ret\r\n\r\ndef scan_file(path: Path) -> Optional[FileReport]:\r\n  try:\r\n    text = path.read_text(encoding=\"utf-8\")\r\n  except Exception:\r\n    return None\r\n  try:\r\n    tree = ast.parse(text, filename=str(path))\r\n  except SyntaxError:\r\n    return None\r\n\r\n  functions: List[FuncReport] = []\r\n  imports = {\"stdlib\": [], \"thirdparty\": [], \"local\": []}\r\n  todos = len(re.findall(r\"(?i)\\\\b(TODO|FIXME|HACK)\\\\b\", text))\r\n  mixed_ws = \"\\\\t\" in text and \"  \" in text  # crude indicator\r\n  trailing_ws = bool(re.search(r\"[ \\\\t]+\\\\n\", text))\r\n\r\n  # imports\r\n  for n in ast.walk(tree):\r\n    if isinstance(n, ast.Import):\r\n      for alias in n.names:\r\n        kind = guess_import_kind(alias.name, path)\r\n        imports[kind].append(alias.name)\r\n    elif isinstance(n, ast.ImportFrom):\r\n      mod = n.module or \"\"\r\n      kind = guess_import_kind(mod if mod else \".\", path)\r\n      imports[kind].append(mod or \".\")\r\n\r\n  # functions\r\n  for n in ast.walk(tree):\r\n    if isinstance(n, (ast.FunctionDef, ast.AsyncFunctionDef)):\r\n      args = [a.arg for a in n.args.args]\r\n      has_doc = ast.get_docstring(n) is not None\r\n      t_args, t_ret = has_type_hints(n)\r\n      comp = naive_complexity(n)\r\n      loc = func_loc(text, n)\r\n      nested = any(isinstance(p, (ast.FunctionDef, ast.AsyncFunctionDef)) for p in ast.walk(n) if p is not n and hasattr(p, \"body\"))\r\n      broad = any(isinstance(e, ast.ExceptHandler) and e.type is None for e in ast.walk(n))\r\n      functions.append(FuncReport(\r\n        name=n.name, lineno=n.lineno, loc=loc, args=args, has_doc=has_doc,\r\n        typed_args=t_args, typed_ret=t_ret, complexity=comp, nested=nested, broad_except=broad\r\n      ))\r\n\r\n  long_funcs = sum(1 for f in functions if f.loc >= LONG_FUNC_LOC)\r\n  high_complexity_funcs = sum(1 for f in functions if f.complexity >= HIGH_COMPLEXITY)\r\n\r\n  return FileReport(\r\n    path=str(path.relative_to(Path.cwd())),\r\n    functions=functions, imports=imports, todos=todos,\r\n    mixed_ws=mixed_ws, trailing_ws=trailing_ws,\r\n    long_funcs=long_funcs, high_complexity_funcs=high_complexity_funcs\r\n  )\r\n\r\ndef discover_py_files(root: Path) -> List[Path]:\r\n  out = []\r\n  for p in root.rglob(\"*.py\"):\r\n    rel = p.relative_to(root)\r\n    if any(part in EXCLUDE_DIRS for part in rel.parts):\r\n      continue\r\n    out.append(p)\r\n  return out\r\n\r\ndef summarize(files: List[FileReport]) -> Dict:\r\n  total_funcs = sum(len(f.functions) for f in files)\r\n  missing_docs = sum(1 for fr in files for fn in fr.functions if not fn.has_doc)\r\n  untyped = sum(1 for fr in files for fn in fr.functions if not (fn.typed_args and fn.typed_ret))\r\n  long_funcs = sum(fr.long_funcs for fr in files)\r\n  high_comp = sum(fr.high_complexity_funcs for fr in files)\r\n  todos = sum(fr.todos for fr in files)\r\n\r\n  # top offenders by complexity/length\r\n  top_by_complex = sorted(\r\n    ((fr.path, fn.name, fn.complexity, fn.lineno) for fr in files for fn in fr.functions),\r\n    key=lambda x: x[2], reverse=True\r\n  )[:10]\r\n  top_by_length = sorted(\r\n    ((fr.path, fn.name, fn.loc, fn.lineno) for fr in files for fn in fr.functions),\r\n    key=lambda x: x[2], reverse=True\r\n  )[:10]\r\n\r\n  return {\r\n    \"files_scanned\": len(files),\r\n    \"functions_total\": total_funcs,\r\n    \"missing_docstrings\": missing_docs,\r\n    \"untyped_functions\": untyped,\r\n    \"long_functions_60+loc\": long_funcs,\r\n    \"high_complexity_10+\": high_comp,\r\n    \"todos_fixme\": todos,\r\n    \"top_complexity\": top_by_complex,\r\n    \"top_length\": top_by_length,\r\n  }\r\n\r\ndef main():\r\n  root = Path.cwd()\r\n  py_files = discover_py_files(root)\r\n  reports: List[FileReport] = []\r\n  for p in py_files:\r\n    fr = scan_file(p)\r\n    if fr:\r\n      reports.append(fr)\r\n\r\n  summary = summarize(reports)\r\n  print(\"# Repo Summary\")\r\n  for k, v in summary.items():\r\n    print(f\"- {k}: {v}\")\r\n\r\n  print(\"\\\\n# Suggestions (first pass)\")\r\n  if summary[\"missing_docstrings\"] > 0:\r\n    print(\"* Add docstrings to public functions (improves UX for readers and IDE help).\")\r\n  if summary[\"untyped_functions\"] > 0:\r\n    print(\"* Add type hints to function signatures + return types for safer refactors.\")\r\n  if summary[\"high_complexity_10+\"] > 0:\r\n    print(\"* Reduce cyclomatic complexity: split into helpers or early returns.\")\r\n  if summary[\"long_functions_60+loc\"] > 0:\r\n    print(\"* Break very long functions (‚â•60 LOC) into smaller units.\")\r\n\r\n  # Optional JSON dump\r\n  out = {\r\n    \"summary\": summary,\r\n    \"files\": [\r\n      {\r\n        **asdict(fr),\r\n        \"functions\": [asdict(fn) for fn in fr.functions],\r\n      }\r\n      for fr in reports\r\n    ]\r\n  }\r\n  (root / \"analysis_report.json\").write_text(json.dumps(out, indent=2), encoding=\"utf-8\")\r\n  print(\"\\\\nWrote analysis_report.json\")\r\n\r\nif __name__ == \"__main__\":\r\n  main()\r\n</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- HOW TO RUN (CODESPACES) -->\r\n    <section class=\"section-card\" id=\"run\">\r\n      <div class=\"banner\">\r\n        <small>Run</small>\r\n        <h1>Run the Analyzer (Codespaces or Local)</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>From your repository root:</p>\r\n<pre>python analyze_repo.py</pre>\r\n        <p>It prints a summary and writes a detailed <span class=\"inline\">analysis_report.json</span> you can commit or review.</p>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- SAMPLE OUTPUT -->\r\n    <section class=\"section-card\" id=\"examples\">\r\n      <div class=\"banner\">\r\n        <small>Examples</small>\r\n        <h1>Sample Findings (What You'll See)</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n<pre># Repo Summary\r\n- files_scanned: 9\r\n- functions_total: 57\r\n- missing_docstrings: 22\r\n- untyped_functions: 31\r\n- long_functions_60+loc: 4\r\n- high_complexity_10+: 5\r\n- todos_fixme: 7\r\n- top_complexity: [('pages/5_Bulk_Upload_CSV.py','_read_one_csv',15,120), ...]\r\n- top_length: [('lib_data.py','sidebar_data_source',98,40), ...]\r\n\r\n# Suggestions (first pass)\r\n* Add docstrings to public functions (improves UX for readers and IDE help).\r\n* Add type hints to function signatures + return types for safer refactors.\r\n* Reduce cyclomatic complexity: split into helpers or early returns.\r\n* Break very long functions (‚â•60 LOC) into smaller units.\r\n\r\nWrote analysis_report.json</pre>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- PROMPTS TO ACT ON RESULTS -->\r\n    <section class=\"section-card\" id=\"prompts\">\r\n      <div class=\"banner\">\r\n        <small>Prompts</small>\r\n        <h1>Turn Findings Into \"One-Thing\" Fixes</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <p>Use your improvement loop to address top items one by one:</p>\r\n        <ul>\r\n          <li><strong>Docstrings:</strong><br>\r\n            <pre>\"Add Google-style docstrings to the 5 longest public functions in lib_data.py. Write the file from A to Z.\"</pre>\r\n          </li>\r\n          <li><strong>Typing:</strong><br>\r\n            <pre>\"Add precise type hints (args + returns) to all functions in bulk_upload_utils.py. Keep behavior identical.\"</pre>\r\n          </li>\r\n          <li><strong>Complexity:</strong><br>\r\n            <pre>\"Reduce complexity of sidebar_data_source() by extracting helpers; limit function to ‚â§ 40 LOC. Write lib_data.py A‚ÜíZ.\"</pre>\r\n          </li>\r\n          <li><strong>Performance:</strong><br>\r\n            <pre>\"Do one thing to make read_one_csv() faster for large files (no behavior changes). Write bulk_upload_utils.py A‚ÜíZ.\"</pre>\r\n          </li>\r\n          <li><strong>UX polish:</strong><br>\r\n            <pre>\"Improve error messages and toasts in pages/5_Bulk_Upload_CSV.py (clear, actionable, short). Write file A‚ÜíZ.\"</pre>\r\n          </li>\r\n        </ul>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- EXTRA CHECKS -->\r\n    <section class=\"section-card\" id=\"extras\">\r\n      <div class=\"banner\">\r\n        <small>Extras</small>\r\n        <h1>Optional Enhancements (If You Want)</h1>\r\n      </div>\r\n      <div class=\"body\">\r\n        <ul>\r\n          <li><strong>Fail CI on regressions:</strong> run <span class=\"inline\">analyze_repo.py</span> in GitHub Actions and diff <span class=\"inline\">analysis_report.json</span>.</li>\r\n          <li><strong>JSON ‚Üí dashboard:</strong> build a small Streamlit page to visualize top offenders and trends over time.</li>\r\n          <li><strong>Strict mode:</strong> raise thresholds (e.g., LONG_FUNC_LOC=40) as quality improves.</li>\r\n        </ul>\r\n      </div>\r\n    </section>\r\n\r\n    <!-- FOOTER -->\r\n    <div class=\"footer-note\">\r\n      ¬© <span id=\"y\"></span> Hawkar ‚Äî Last updated <span id=\"d\"></span>\r\n    </div>\r\n\r\n  </div>\r\n\r\n<script>\r\n(function(){\r\n  const now = new Date();\r\n  document.getElementById('y').textContent = now.getFullYear();\r\n  document.getElementById('d').textContent = now.toLocaleDateString(\r\n    undefined, {year:'numeric', month:'short', day:'2-digit'}\r\n  );\r\n})();\r\n</script>\r\n</body>\r\n</html>"
      },
      "lesson_uid": "ee1aa3ee-7827-4b8f-8b4d-0a68d18901b7"
    }
  ]
}